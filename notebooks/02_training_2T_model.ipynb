{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training pipeline: Training Two Tower model\n",
    "\n",
    "In this notebook, We will train a retrieval model that will be able to quickly generate a small subset of Users events from a large collection of bets. The Model is based on the two-tower architecture, which embeds Users Inputs (Query) and bets (bet_ids) into a shared low-dimensional vector space. Here, a query consists of features of a Users and a bets (e.g. timestamp of the events), whereas a events consists of features of a particular bet. All queries will have a user ID and all bets will have an bet ID, and the model will be trained such that the embedding of a user will be close to all the embeddings of bets the user has previously bought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pickle\n",
    "import torch\n",
    "from recsys.config import settings\n",
    "from recsys.train import train_test_split, experiment\n",
    "from recsys.models import two_tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the training data\n",
    "feature_dir = settings.PROCESSED_DATA_DIR\n",
    "with open(feature_dir / 'features_dataset.pickle', 'rb') as handle:\n",
    "    features_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data, val_data = train_test_split.get_train_val_split(features_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User features dimension: 7\n",
      "Event features dimension: 3\n"
     ]
    }
   ],
   "source": [
    "model = two_tower.initialize_model(dataset=features_data, device=settings.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion, optimizer = two_tower.setup_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/4501], Loss: 1.6773, Accuracy: 60.72%\n",
      "Epoch [1/10], Step [200/4501], Loss: 0.5641, Accuracy: 83.03%\n",
      "Epoch [1/10], Step [300/4501], Loss: 0.3967, Accuracy: 87.59%\n",
      "Epoch [1/10], Step [400/4501], Loss: 0.3434, Accuracy: 89.69%\n",
      "Epoch [1/10], Step [500/4501], Loss: 0.2834, Accuracy: 91.66%\n",
      "Epoch [1/10], Step [600/4501], Loss: 0.2939, Accuracy: 91.22%\n",
      "Epoch [1/10], Step [700/4501], Loss: 0.2589, Accuracy: 91.59%\n",
      "Epoch [1/10], Step [800/4501], Loss: 0.2427, Accuracy: 91.97%\n",
      "Epoch [1/10], Step [900/4501], Loss: 0.3160, Accuracy: 90.53%\n",
      "Epoch [1/10], Step [1000/4501], Loss: 0.2438, Accuracy: 91.91%\n",
      "Epoch [1/10], Step [1100/4501], Loss: 0.2303, Accuracy: 92.50%\n",
      "Epoch [1/10], Step [1200/4501], Loss: 0.2345, Accuracy: 91.38%\n",
      "Epoch [1/10], Step [1300/4501], Loss: 0.2302, Accuracy: 92.38%\n",
      "Epoch [1/10], Step [1400/4501], Loss: 0.2029, Accuracy: 92.44%\n",
      "Epoch [1/10], Step [1500/4501], Loss: 0.2164, Accuracy: 93.19%\n",
      "Epoch [1/10], Step [1600/4501], Loss: 0.2482, Accuracy: 91.97%\n",
      "Epoch [1/10], Step [1700/4501], Loss: 0.2010, Accuracy: 93.12%\n",
      "Epoch [1/10], Step [1800/4501], Loss: 0.2166, Accuracy: 92.53%\n",
      "Epoch [1/10], Step [1900/4501], Loss: 0.1960, Accuracy: 92.47%\n",
      "Epoch [1/10], Step [2000/4501], Loss: 0.2052, Accuracy: 93.34%\n",
      "Epoch [1/10], Step [2100/4501], Loss: 0.1805, Accuracy: 93.41%\n",
      "Epoch [1/10], Step [2200/4501], Loss: 0.1936, Accuracy: 93.12%\n",
      "Epoch [1/10], Step [2300/4501], Loss: 0.2051, Accuracy: 91.91%\n",
      "Epoch [1/10], Step [2400/4501], Loss: 0.2050, Accuracy: 92.62%\n",
      "Epoch [1/10], Step [2500/4501], Loss: 0.1809, Accuracy: 93.72%\n",
      "Epoch [1/10], Step [2600/4501], Loss: 0.2019, Accuracy: 93.41%\n",
      "Epoch [1/10], Step [2700/4501], Loss: 0.1982, Accuracy: 92.97%\n",
      "Epoch [1/10], Step [2800/4501], Loss: 0.1899, Accuracy: 93.62%\n",
      "Epoch [1/10], Step [2900/4501], Loss: 0.1740, Accuracy: 93.59%\n",
      "Epoch [1/10], Step [3000/4501], Loss: 0.2004, Accuracy: 93.00%\n",
      "Epoch [1/10], Step [3100/4501], Loss: 0.1848, Accuracy: 93.78%\n",
      "Epoch [1/10], Step [3200/4501], Loss: 0.1974, Accuracy: 92.81%\n",
      "Epoch [1/10], Step [3300/4501], Loss: 0.1806, Accuracy: 93.62%\n",
      "Epoch [1/10], Step [3400/4501], Loss: 0.1926, Accuracy: 93.59%\n",
      "Epoch [1/10], Step [3500/4501], Loss: 0.2012, Accuracy: 93.00%\n",
      "Epoch [1/10], Step [3600/4501], Loss: 0.2078, Accuracy: 93.12%\n",
      "Epoch [1/10], Step [3700/4501], Loss: 0.1930, Accuracy: 93.00%\n",
      "Epoch [1/10], Step [3800/4501], Loss: 0.1893, Accuracy: 92.88%\n",
      "Epoch [1/10], Step [3900/4501], Loss: 0.1871, Accuracy: 93.53%\n",
      "Epoch [1/10], Step [4000/4501], Loss: 0.1768, Accuracy: 94.00%\n",
      "Epoch [1/10], Step [4100/4501], Loss: 0.2314, Accuracy: 93.31%\n",
      "Epoch [1/10], Step [4200/4501], Loss: 0.2044, Accuracy: 92.56%\n",
      "Epoch [1/10], Step [4300/4501], Loss: 0.1675, Accuracy: 94.41%\n",
      "Epoch [1/10], Step [4400/4501], Loss: 0.1588, Accuracy: 94.19%\n",
      "Epoch [1/10], Step [4500/4501], Loss: 0.1809, Accuracy: 93.25%\n",
      "Epoch [1/10], Val Loss: 0.1701, Val Accuracy: 94.07%\n",
      "Epoch [2/10], Step [100/4501], Loss: 0.1796, Accuracy: 93.75%\n",
      "Epoch [2/10], Step [200/4501], Loss: 0.1703, Accuracy: 93.38%\n",
      "Epoch [2/10], Step [300/4501], Loss: 0.1942, Accuracy: 93.41%\n",
      "Epoch [2/10], Step [400/4501], Loss: 0.1725, Accuracy: 93.69%\n",
      "Epoch [2/10], Step [500/4501], Loss: 0.1713, Accuracy: 93.56%\n",
      "Epoch [2/10], Step [600/4501], Loss: 0.1582, Accuracy: 93.97%\n",
      "Epoch [2/10], Step [700/4501], Loss: 0.1824, Accuracy: 93.59%\n",
      "Epoch [2/10], Step [800/4501], Loss: 0.1816, Accuracy: 93.94%\n",
      "Epoch [2/10], Step [900/4501], Loss: 0.1978, Accuracy: 93.88%\n",
      "Epoch [2/10], Step [1000/4501], Loss: 0.2024, Accuracy: 93.12%\n",
      "Epoch [2/10], Step [1100/4501], Loss: 0.1632, Accuracy: 93.81%\n",
      "Epoch [2/10], Step [1200/4501], Loss: 0.1573, Accuracy: 94.19%\n",
      "Epoch [2/10], Step [1300/4501], Loss: 0.1706, Accuracy: 93.66%\n",
      "Epoch [2/10], Step [1400/4501], Loss: 0.1816, Accuracy: 93.44%\n",
      "Epoch [2/10], Step [1500/4501], Loss: 0.1855, Accuracy: 92.81%\n",
      "Epoch [2/10], Step [1600/4501], Loss: 0.1695, Accuracy: 93.91%\n",
      "Epoch [2/10], Step [1700/4501], Loss: 0.1600, Accuracy: 94.31%\n",
      "Epoch [2/10], Step [1800/4501], Loss: 0.1799, Accuracy: 93.50%\n",
      "Epoch [2/10], Step [1900/4501], Loss: 0.1812, Accuracy: 93.12%\n",
      "Epoch [2/10], Step [2000/4501], Loss: 0.1603, Accuracy: 94.06%\n",
      "Epoch [2/10], Step [2100/4501], Loss: 0.1761, Accuracy: 93.34%\n",
      "Epoch [2/10], Step [2200/4501], Loss: 0.1853, Accuracy: 93.41%\n",
      "Epoch [2/10], Step [2300/4501], Loss: 0.1650, Accuracy: 93.66%\n",
      "Epoch [2/10], Step [2400/4501], Loss: 0.1845, Accuracy: 93.06%\n",
      "Epoch [2/10], Step [2500/4501], Loss: 0.2015, Accuracy: 92.97%\n",
      "Epoch [2/10], Step [2600/4501], Loss: 0.1964, Accuracy: 92.50%\n",
      "Epoch [2/10], Step [2700/4501], Loss: 0.1725, Accuracy: 93.44%\n",
      "Epoch [2/10], Step [2800/4501], Loss: 0.1681, Accuracy: 93.28%\n",
      "Epoch [2/10], Step [2900/4501], Loss: 0.1770, Accuracy: 93.78%\n",
      "Epoch [2/10], Step [3000/4501], Loss: 0.1450, Accuracy: 93.88%\n",
      "Epoch [2/10], Step [3100/4501], Loss: 0.1658, Accuracy: 94.25%\n",
      "Epoch [2/10], Step [3200/4501], Loss: 0.1843, Accuracy: 93.66%\n",
      "Epoch [2/10], Step [3300/4501], Loss: 0.1630, Accuracy: 94.22%\n",
      "Epoch [2/10], Step [3400/4501], Loss: 0.1601, Accuracy: 93.88%\n",
      "Epoch [2/10], Step [3500/4501], Loss: 0.1470, Accuracy: 94.62%\n",
      "Epoch [2/10], Step [3600/4501], Loss: 0.1797, Accuracy: 93.38%\n",
      "Epoch [2/10], Step [3700/4501], Loss: 0.1518, Accuracy: 94.16%\n",
      "Epoch [2/10], Step [3800/4501], Loss: 0.1506, Accuracy: 94.81%\n",
      "Epoch [2/10], Step [3900/4501], Loss: 0.1798, Accuracy: 93.88%\n",
      "Epoch [2/10], Step [4000/4501], Loss: 0.1669, Accuracy: 94.62%\n",
      "Epoch [2/10], Step [4100/4501], Loss: 0.1556, Accuracy: 94.53%\n",
      "Epoch [2/10], Step [4200/4501], Loss: 0.1698, Accuracy: 94.53%\n",
      "Epoch [2/10], Step [4300/4501], Loss: 0.1547, Accuracy: 95.03%\n",
      "Epoch [2/10], Step [4400/4501], Loss: 0.1715, Accuracy: 94.03%\n",
      "Epoch [2/10], Step [4500/4501], Loss: 0.1559, Accuracy: 94.34%\n",
      "Epoch [2/10], Val Loss: 0.1342, Val Accuracy: 95.79%\n",
      "Epoch [3/10], Step [100/4501], Loss: 0.1535, Accuracy: 94.44%\n",
      "Epoch [3/10], Step [200/4501], Loss: 0.1473, Accuracy: 94.56%\n",
      "Epoch [3/10], Step [300/4501], Loss: 0.1689, Accuracy: 93.84%\n",
      "Epoch [3/10], Step [400/4501], Loss: 0.1658, Accuracy: 94.25%\n",
      "Epoch [3/10], Step [500/4501], Loss: 0.1451, Accuracy: 94.72%\n",
      "Epoch [3/10], Step [600/4501], Loss: 0.1574, Accuracy: 94.38%\n",
      "Epoch [3/10], Step [700/4501], Loss: 0.1563, Accuracy: 94.56%\n",
      "Epoch [3/10], Step [800/4501], Loss: 0.1669, Accuracy: 93.97%\n",
      "Epoch [3/10], Step [900/4501], Loss: 0.1640, Accuracy: 94.28%\n",
      "Epoch [3/10], Step [1000/4501], Loss: 0.1602, Accuracy: 94.31%\n",
      "Epoch [3/10], Step [1100/4501], Loss: 0.1614, Accuracy: 94.38%\n",
      "Epoch [3/10], Step [1200/4501], Loss: 0.1542, Accuracy: 94.59%\n",
      "Epoch [3/10], Step [1300/4501], Loss: 0.1541, Accuracy: 94.62%\n",
      "Epoch [3/10], Step [1400/4501], Loss: 0.1470, Accuracy: 95.06%\n",
      "Epoch [3/10], Step [1500/4501], Loss: 0.1452, Accuracy: 94.47%\n",
      "Epoch [3/10], Step [1600/4501], Loss: 0.1391, Accuracy: 95.03%\n",
      "Epoch [3/10], Step [1700/4501], Loss: 0.1473, Accuracy: 94.81%\n",
      "Epoch [3/10], Step [1800/4501], Loss: 0.1447, Accuracy: 94.75%\n",
      "Epoch [3/10], Step [1900/4501], Loss: 0.1608, Accuracy: 94.16%\n",
      "Epoch [3/10], Step [2000/4501], Loss: 0.1398, Accuracy: 94.94%\n",
      "Epoch [3/10], Step [2100/4501], Loss: 0.1255, Accuracy: 95.66%\n",
      "Epoch [3/10], Step [2200/4501], Loss: 0.1548, Accuracy: 94.59%\n",
      "Epoch [3/10], Step [2300/4501], Loss: 0.1596, Accuracy: 94.38%\n",
      "Epoch [3/10], Step [2400/4501], Loss: 0.1470, Accuracy: 94.94%\n",
      "Epoch [3/10], Step [2500/4501], Loss: 0.1461, Accuracy: 94.69%\n",
      "Epoch [3/10], Step [2600/4501], Loss: 0.1443, Accuracy: 94.53%\n",
      "Epoch [3/10], Step [2700/4501], Loss: 0.1504, Accuracy: 94.84%\n",
      "Epoch [3/10], Step [2800/4501], Loss: 0.1434, Accuracy: 95.06%\n",
      "Epoch [3/10], Step [2900/4501], Loss: 0.1625, Accuracy: 94.75%\n",
      "Epoch [3/10], Step [3000/4501], Loss: 0.1541, Accuracy: 94.56%\n",
      "Epoch [3/10], Step [3100/4501], Loss: 0.1546, Accuracy: 94.62%\n",
      "Epoch [3/10], Step [3200/4501], Loss: 0.1608, Accuracy: 94.06%\n",
      "Epoch [3/10], Step [3300/4501], Loss: 0.1540, Accuracy: 94.62%\n",
      "Epoch [3/10], Step [3400/4501], Loss: 0.1384, Accuracy: 95.16%\n",
      "Epoch [3/10], Step [3500/4501], Loss: 0.1563, Accuracy: 94.81%\n",
      "Epoch [3/10], Step [3600/4501], Loss: 0.1387, Accuracy: 95.00%\n",
      "Epoch [3/10], Step [3700/4501], Loss: 0.1736, Accuracy: 93.97%\n",
      "Epoch [3/10], Step [3800/4501], Loss: 0.1368, Accuracy: 95.34%\n",
      "Epoch [3/10], Step [3900/4501], Loss: 0.1452, Accuracy: 95.31%\n",
      "Epoch [3/10], Step [4000/4501], Loss: 0.1310, Accuracy: 95.28%\n",
      "Epoch [3/10], Step [4100/4501], Loss: 0.1581, Accuracy: 94.03%\n",
      "Epoch [3/10], Step [4200/4501], Loss: 0.1496, Accuracy: 94.44%\n",
      "Epoch [3/10], Step [4300/4501], Loss: 0.1575, Accuracy: 94.50%\n",
      "Epoch [3/10], Step [4400/4501], Loss: 0.1457, Accuracy: 94.59%\n",
      "Epoch [3/10], Step [4500/4501], Loss: 0.1389, Accuracy: 95.22%\n",
      "Epoch [3/10], Val Loss: 0.4149, Val Accuracy: 94.50%\n",
      "Epoch [4/10], Step [100/4501], Loss: 0.1423, Accuracy: 95.12%\n",
      "Epoch [4/10], Step [200/4501], Loss: 0.1346, Accuracy: 95.28%\n",
      "Epoch [4/10], Step [300/4501], Loss: 0.1438, Accuracy: 95.44%\n",
      "Epoch [4/10], Step [400/4501], Loss: 0.1282, Accuracy: 95.59%\n",
      "Epoch [4/10], Step [500/4501], Loss: 0.1260, Accuracy: 95.50%\n",
      "Epoch [4/10], Step [600/4501], Loss: 0.1529, Accuracy: 94.81%\n",
      "Epoch [4/10], Step [700/4501], Loss: 0.1261, Accuracy: 95.19%\n",
      "Epoch [4/10], Step [800/4501], Loss: 0.1496, Accuracy: 94.97%\n",
      "Epoch [4/10], Step [900/4501], Loss: 0.1456, Accuracy: 94.88%\n",
      "Epoch [4/10], Step [1000/4501], Loss: 0.1234, Accuracy: 95.38%\n",
      "Epoch [4/10], Step [1100/4501], Loss: 0.1492, Accuracy: 94.12%\n",
      "Epoch [4/10], Step [1200/4501], Loss: 0.1277, Accuracy: 95.41%\n",
      "Epoch [4/10], Step [1300/4501], Loss: 0.1312, Accuracy: 95.22%\n",
      "Epoch [4/10], Step [1400/4501], Loss: 0.1393, Accuracy: 94.75%\n",
      "Epoch [4/10], Step [1500/4501], Loss: 0.1348, Accuracy: 95.81%\n",
      "Epoch [4/10], Step [1600/4501], Loss: 0.1303, Accuracy: 95.38%\n",
      "Epoch [4/10], Step [1700/4501], Loss: 0.1287, Accuracy: 95.41%\n",
      "Epoch [4/10], Step [1800/4501], Loss: 0.1256, Accuracy: 95.41%\n",
      "Epoch [4/10], Step [1900/4501], Loss: 0.1610, Accuracy: 94.84%\n",
      "Epoch [4/10], Step [2000/4501], Loss: 0.1367, Accuracy: 95.28%\n",
      "Epoch [4/10], Step [2100/4501], Loss: 0.1407, Accuracy: 95.47%\n",
      "Epoch [4/10], Step [2200/4501], Loss: 0.1214, Accuracy: 95.97%\n",
      "Epoch [4/10], Step [2300/4501], Loss: 0.1242, Accuracy: 95.47%\n",
      "Epoch [4/10], Step [2400/4501], Loss: 0.1483, Accuracy: 94.94%\n",
      "Epoch [4/10], Step [2500/4501], Loss: 0.1498, Accuracy: 95.00%\n",
      "Epoch [4/10], Step [2600/4501], Loss: 0.1407, Accuracy: 94.94%\n",
      "Epoch [4/10], Step [2700/4501], Loss: 0.1417, Accuracy: 94.91%\n",
      "Epoch [4/10], Step [2800/4501], Loss: 0.1340, Accuracy: 95.53%\n",
      "Epoch [4/10], Step [2900/4501], Loss: 0.1198, Accuracy: 95.47%\n",
      "Epoch [4/10], Step [3000/4501], Loss: 0.1199, Accuracy: 96.41%\n",
      "Epoch [4/10], Step [3100/4501], Loss: 0.1286, Accuracy: 95.28%\n",
      "Epoch [4/10], Step [3200/4501], Loss: 0.1310, Accuracy: 95.09%\n",
      "Epoch [4/10], Step [3300/4501], Loss: 0.1374, Accuracy: 95.31%\n",
      "Epoch [4/10], Step [3400/4501], Loss: 0.1254, Accuracy: 95.56%\n",
      "Epoch [4/10], Step [3500/4501], Loss: 0.1364, Accuracy: 95.38%\n",
      "Epoch [4/10], Step [3600/4501], Loss: 0.1535, Accuracy: 95.06%\n",
      "Epoch [4/10], Step [3700/4501], Loss: 0.1333, Accuracy: 95.28%\n",
      "Epoch [4/10], Step [3800/4501], Loss: 0.1345, Accuracy: 95.06%\n",
      "Epoch [4/10], Step [3900/4501], Loss: 0.1665, Accuracy: 95.16%\n",
      "Epoch [4/10], Step [4000/4501], Loss: 0.1408, Accuracy: 95.19%\n",
      "Epoch [4/10], Step [4100/4501], Loss: 0.1299, Accuracy: 95.31%\n",
      "Epoch [4/10], Step [4200/4501], Loss: 0.1370, Accuracy: 94.94%\n",
      "Epoch [4/10], Step [4300/4501], Loss: 0.1414, Accuracy: 94.94%\n",
      "Epoch [4/10], Step [4400/4501], Loss: 0.1389, Accuracy: 95.38%\n",
      "Epoch [4/10], Step [4500/4501], Loss: 0.1156, Accuracy: 96.22%\n",
      "Epoch [4/10], Val Loss: 0.1540, Val Accuracy: 94.87%\n",
      "Epoch [5/10], Step [100/4501], Loss: 0.1465, Accuracy: 95.12%\n",
      "Epoch [5/10], Step [200/4501], Loss: 0.1311, Accuracy: 95.22%\n",
      "Epoch [5/10], Step [300/4501], Loss: 0.1133, Accuracy: 96.22%\n",
      "Epoch [5/10], Step [400/4501], Loss: 0.1355, Accuracy: 95.16%\n",
      "Epoch [5/10], Step [500/4501], Loss: 0.1060, Accuracy: 96.06%\n",
      "Epoch [5/10], Step [600/4501], Loss: 0.1653, Accuracy: 94.41%\n",
      "Epoch [5/10], Step [700/4501], Loss: 0.1215, Accuracy: 95.66%\n",
      "Epoch [5/10], Step [800/4501], Loss: 0.1270, Accuracy: 95.56%\n",
      "Epoch [5/10], Step [900/4501], Loss: 0.1309, Accuracy: 95.41%\n",
      "Epoch [5/10], Step [1000/4501], Loss: 0.1309, Accuracy: 95.41%\n",
      "Epoch [5/10], Step [1100/4501], Loss: 0.1297, Accuracy: 95.44%\n",
      "Epoch [5/10], Step [1200/4501], Loss: 0.1216, Accuracy: 96.00%\n",
      "Epoch [5/10], Step [1300/4501], Loss: 0.1318, Accuracy: 95.47%\n",
      "Epoch [5/10], Step [1400/4501], Loss: 0.1298, Accuracy: 95.84%\n",
      "Epoch [5/10], Step [1500/4501], Loss: 0.1396, Accuracy: 95.53%\n",
      "Epoch [5/10], Step [1600/4501], Loss: 0.1508, Accuracy: 95.00%\n",
      "Epoch [5/10], Step [1700/4501], Loss: 0.1176, Accuracy: 95.91%\n",
      "Epoch [5/10], Step [1800/4501], Loss: 0.1274, Accuracy: 95.78%\n",
      "Epoch [5/10], Step [1900/4501], Loss: 0.1538, Accuracy: 94.97%\n",
      "Epoch [5/10], Step [2000/4501], Loss: 0.1431, Accuracy: 94.72%\n",
      "Epoch [5/10], Step [2100/4501], Loss: 0.1118, Accuracy: 96.12%\n",
      "Epoch [5/10], Step [2200/4501], Loss: 0.1416, Accuracy: 95.19%\n",
      "Epoch [5/10], Step [2300/4501], Loss: 0.1200, Accuracy: 95.84%\n",
      "Epoch [5/10], Step [2400/4501], Loss: 0.1488, Accuracy: 95.09%\n",
      "Epoch [5/10], Step [2500/4501], Loss: 0.1293, Accuracy: 95.62%\n",
      "Epoch [5/10], Step [2600/4501], Loss: 0.1169, Accuracy: 95.81%\n",
      "Epoch [5/10], Step [2700/4501], Loss: 0.1326, Accuracy: 95.66%\n",
      "Epoch [5/10], Step [2800/4501], Loss: 0.1178, Accuracy: 96.00%\n",
      "Epoch [5/10], Step [2900/4501], Loss: 0.1187, Accuracy: 95.34%\n",
      "Epoch [5/10], Step [3000/4501], Loss: 0.1139, Accuracy: 96.16%\n",
      "Epoch [5/10], Step [3100/4501], Loss: 0.1316, Accuracy: 95.34%\n",
      "Epoch [5/10], Step [3200/4501], Loss: 0.1226, Accuracy: 96.03%\n",
      "Epoch [5/10], Step [3300/4501], Loss: 0.1363, Accuracy: 95.50%\n",
      "Epoch [5/10], Step [3400/4501], Loss: 0.1376, Accuracy: 95.22%\n",
      "Epoch [5/10], Step [3500/4501], Loss: 0.1419, Accuracy: 95.03%\n",
      "Epoch [5/10], Step [3600/4501], Loss: 0.1300, Accuracy: 95.16%\n",
      "Epoch [5/10], Step [3700/4501], Loss: 0.1538, Accuracy: 94.56%\n",
      "Epoch [5/10], Step [3800/4501], Loss: 0.1391, Accuracy: 95.38%\n",
      "Epoch [5/10], Step [3900/4501], Loss: 0.1227, Accuracy: 95.84%\n",
      "Epoch [5/10], Step [4000/4501], Loss: 0.1259, Accuracy: 95.91%\n",
      "Epoch [5/10], Step [4100/4501], Loss: 0.1344, Accuracy: 95.62%\n",
      "Epoch [5/10], Step [4200/4501], Loss: 0.1424, Accuracy: 94.91%\n",
      "Epoch [5/10], Step [4300/4501], Loss: 0.1396, Accuracy: 95.50%\n",
      "Epoch [5/10], Step [4400/4501], Loss: 0.1251, Accuracy: 94.97%\n",
      "Epoch [5/10], Step [4500/4501], Loss: 0.1137, Accuracy: 96.25%\n",
      "Epoch [5/10], Val Loss: 7.3168, Val Accuracy: 95.23%\n",
      "Epoch [6/10], Step [100/4501], Loss: 0.1364, Accuracy: 95.94%\n",
      "Epoch [6/10], Step [200/4501], Loss: 0.1324, Accuracy: 95.59%\n",
      "Epoch [6/10], Step [300/4501], Loss: 0.1236, Accuracy: 95.97%\n",
      "Epoch [6/10], Step [400/4501], Loss: 0.1444, Accuracy: 95.41%\n",
      "Epoch [6/10], Step [500/4501], Loss: 0.1314, Accuracy: 95.56%\n",
      "Epoch [6/10], Step [600/4501], Loss: 0.1321, Accuracy: 95.69%\n",
      "Epoch [6/10], Step [700/4501], Loss: 0.1227, Accuracy: 95.41%\n",
      "Epoch [6/10], Step [800/4501], Loss: 0.1486, Accuracy: 95.50%\n",
      "Epoch [6/10], Step [900/4501], Loss: 0.1353, Accuracy: 95.81%\n",
      "Epoch [6/10], Step [1000/4501], Loss: 0.1377, Accuracy: 95.53%\n",
      "Epoch [6/10], Step [1100/4501], Loss: 0.1310, Accuracy: 95.00%\n",
      "Epoch [6/10], Step [1200/4501], Loss: 0.1333, Accuracy: 95.31%\n",
      "Epoch [6/10], Step [1300/4501], Loss: 0.1426, Accuracy: 95.34%\n",
      "Epoch [6/10], Step [1400/4501], Loss: 0.1358, Accuracy: 95.28%\n",
      "Epoch [6/10], Step [1500/4501], Loss: 0.1434, Accuracy: 95.34%\n",
      "Epoch [6/10], Step [1600/4501], Loss: 0.1362, Accuracy: 95.38%\n",
      "Epoch [6/10], Step [1700/4501], Loss: 0.1354, Accuracy: 95.03%\n",
      "Epoch [6/10], Step [1800/4501], Loss: 0.1314, Accuracy: 95.00%\n",
      "Epoch [6/10], Step [1900/4501], Loss: 0.1332, Accuracy: 94.91%\n",
      "Epoch [6/10], Step [2000/4501], Loss: 0.1384, Accuracy: 94.97%\n",
      "Epoch [6/10], Step [2100/4501], Loss: 0.1167, Accuracy: 95.78%\n",
      "Epoch [6/10], Step [2200/4501], Loss: 0.1224, Accuracy: 95.59%\n",
      "Epoch [6/10], Step [2300/4501], Loss: 0.1300, Accuracy: 95.66%\n",
      "Epoch [6/10], Step [2400/4501], Loss: 0.1254, Accuracy: 95.47%\n",
      "Epoch [6/10], Step [2500/4501], Loss: 0.1081, Accuracy: 96.56%\n",
      "Epoch [6/10], Step [2600/4501], Loss: 0.1321, Accuracy: 95.47%\n",
      "Epoch [6/10], Step [2700/4501], Loss: 0.1336, Accuracy: 95.53%\n",
      "Epoch [6/10], Step [2800/4501], Loss: 0.1262, Accuracy: 95.38%\n",
      "Epoch [6/10], Step [2900/4501], Loss: 0.1195, Accuracy: 95.75%\n",
      "Epoch [6/10], Step [3000/4501], Loss: 0.1179, Accuracy: 95.94%\n",
      "Epoch [6/10], Step [3100/4501], Loss: 0.1320, Accuracy: 95.59%\n",
      "Epoch [6/10], Step [3200/4501], Loss: 0.1317, Accuracy: 95.56%\n",
      "Epoch [6/10], Step [3300/4501], Loss: 0.1247, Accuracy: 95.19%\n",
      "Epoch [6/10], Step [3400/4501], Loss: 0.1198, Accuracy: 96.16%\n",
      "Epoch [6/10], Step [3500/4501], Loss: 0.1333, Accuracy: 95.41%\n",
      "Epoch [6/10], Step [3600/4501], Loss: 0.1388, Accuracy: 95.25%\n",
      "Epoch [6/10], Step [3700/4501], Loss: 0.1318, Accuracy: 95.44%\n",
      "Epoch [6/10], Step [3800/4501], Loss: 0.1293, Accuracy: 95.41%\n",
      "Epoch [6/10], Step [3900/4501], Loss: 0.1305, Accuracy: 95.16%\n",
      "Epoch [6/10], Step [4000/4501], Loss: 0.1171, Accuracy: 95.94%\n",
      "Epoch [6/10], Step [4100/4501], Loss: 0.1376, Accuracy: 95.28%\n",
      "Epoch [6/10], Step [4200/4501], Loss: 0.1294, Accuracy: 95.69%\n",
      "Epoch [6/10], Step [4300/4501], Loss: 0.1308, Accuracy: 95.53%\n",
      "Epoch [6/10], Step [4400/4501], Loss: 0.1239, Accuracy: 95.94%\n",
      "Epoch [6/10], Step [4500/4501], Loss: 0.1292, Accuracy: 95.69%\n",
      "Epoch [6/10], Val Loss: 21.3261, Val Accuracy: 95.77%\n",
      "Epoch [7/10], Step [100/4501], Loss: 0.1306, Accuracy: 95.69%\n",
      "Epoch [7/10], Step [200/4501], Loss: 0.1322, Accuracy: 94.94%\n",
      "Epoch [7/10], Step [300/4501], Loss: 0.1296, Accuracy: 95.81%\n",
      "Epoch [7/10], Step [400/4501], Loss: 0.1389, Accuracy: 95.06%\n",
      "Epoch [7/10], Step [500/4501], Loss: 0.1202, Accuracy: 95.44%\n",
      "Epoch [7/10], Step [600/4501], Loss: 0.1135, Accuracy: 96.06%\n",
      "Epoch [7/10], Step [700/4501], Loss: 0.1403, Accuracy: 95.09%\n",
      "Epoch [7/10], Step [800/4501], Loss: 0.1300, Accuracy: 95.66%\n",
      "Epoch [7/10], Step [900/4501], Loss: 0.1364, Accuracy: 95.19%\n",
      "Epoch [7/10], Step [1000/4501], Loss: 0.1330, Accuracy: 94.88%\n",
      "Epoch [7/10], Step [1100/4501], Loss: 0.1287, Accuracy: 95.78%\n",
      "Epoch [7/10], Step [1200/4501], Loss: 0.1311, Accuracy: 95.44%\n",
      "Epoch [7/10], Step [1300/4501], Loss: 0.1149, Accuracy: 95.91%\n",
      "Epoch [7/10], Step [1400/4501], Loss: 0.1163, Accuracy: 95.78%\n",
      "Epoch [7/10], Step [1500/4501], Loss: 0.1425, Accuracy: 95.41%\n",
      "Epoch [7/10], Step [1600/4501], Loss: 0.1230, Accuracy: 95.59%\n",
      "Epoch [7/10], Step [1700/4501], Loss: 0.1205, Accuracy: 95.56%\n",
      "Epoch [7/10], Step [1800/4501], Loss: 0.1196, Accuracy: 95.62%\n",
      "Epoch [7/10], Step [1900/4501], Loss: 0.1178, Accuracy: 95.75%\n",
      "Epoch [7/10], Step [2000/4501], Loss: 0.1352, Accuracy: 95.09%\n",
      "Epoch [7/10], Step [2100/4501], Loss: 0.1365, Accuracy: 95.09%\n",
      "Epoch [7/10], Step [2200/4501], Loss: 0.1255, Accuracy: 95.84%\n",
      "Epoch [7/10], Step [2300/4501], Loss: 0.1227, Accuracy: 95.62%\n",
      "Epoch [7/10], Step [2400/4501], Loss: 0.1196, Accuracy: 96.03%\n",
      "Epoch [7/10], Step [2500/4501], Loss: 0.1302, Accuracy: 95.84%\n",
      "Epoch [7/10], Step [2600/4501], Loss: 0.1500, Accuracy: 94.69%\n",
      "Epoch [7/10], Step [2700/4501], Loss: 0.1380, Accuracy: 95.16%\n",
      "Epoch [7/10], Step [2800/4501], Loss: 0.1455, Accuracy: 95.34%\n",
      "Epoch [7/10], Step [2900/4501], Loss: 0.1197, Accuracy: 95.88%\n",
      "Epoch [7/10], Step [3000/4501], Loss: 0.1344, Accuracy: 95.50%\n",
      "Epoch [7/10], Step [3100/4501], Loss: 0.1176, Accuracy: 95.81%\n",
      "Epoch [7/10], Step [3200/4501], Loss: 0.1207, Accuracy: 95.56%\n",
      "Epoch [7/10], Step [3300/4501], Loss: 0.1337, Accuracy: 95.59%\n",
      "Epoch [7/10], Step [3400/4501], Loss: 0.1386, Accuracy: 95.25%\n",
      "Epoch [7/10], Step [3500/4501], Loss: 0.1337, Accuracy: 95.00%\n",
      "Epoch [7/10], Step [3600/4501], Loss: 0.1286, Accuracy: 95.41%\n",
      "Epoch [7/10], Step [3700/4501], Loss: 0.1321, Accuracy: 95.22%\n",
      "Epoch [7/10], Step [3800/4501], Loss: 0.1176, Accuracy: 95.34%\n",
      "Epoch [7/10], Step [3900/4501], Loss: 0.1220, Accuracy: 95.84%\n",
      "Epoch [7/10], Step [4000/4501], Loss: 0.1227, Accuracy: 95.91%\n",
      "Epoch [7/10], Step [4100/4501], Loss: 0.1517, Accuracy: 95.16%\n",
      "Epoch [7/10], Step [4200/4501], Loss: 0.1273, Accuracy: 95.44%\n",
      "Epoch [7/10], Step [4300/4501], Loss: 0.1409, Accuracy: 95.38%\n",
      "Epoch [7/10], Step [4400/4501], Loss: 0.1239, Accuracy: 95.56%\n",
      "Epoch [7/10], Step [4500/4501], Loss: 0.1236, Accuracy: 95.38%\n",
      "Epoch [7/10], Val Loss: 72.9950, Val Accuracy: 95.05%\n",
      "Epoch [8/10], Step [100/4501], Loss: 0.1210, Accuracy: 95.25%\n",
      "Epoch [8/10], Step [200/4501], Loss: 0.1402, Accuracy: 95.12%\n",
      "Epoch [8/10], Step [300/4501], Loss: 0.1350, Accuracy: 95.28%\n",
      "Epoch [8/10], Step [400/4501], Loss: 0.1289, Accuracy: 95.44%\n",
      "Epoch [8/10], Step [500/4501], Loss: 0.1119, Accuracy: 96.25%\n",
      "Epoch [8/10], Step [600/4501], Loss: 0.1123, Accuracy: 96.41%\n",
      "Epoch [8/10], Step [700/4501], Loss: 0.1353, Accuracy: 95.16%\n",
      "Epoch [8/10], Step [800/4501], Loss: 0.1277, Accuracy: 95.28%\n",
      "Epoch [8/10], Step [900/4501], Loss: 0.1220, Accuracy: 95.78%\n",
      "Epoch [8/10], Step [1000/4501], Loss: 0.1285, Accuracy: 95.06%\n",
      "Epoch [8/10], Step [1100/4501], Loss: 0.1349, Accuracy: 95.03%\n",
      "Epoch [8/10], Step [1200/4501], Loss: 0.1280, Accuracy: 95.16%\n",
      "Epoch [8/10], Step [1300/4501], Loss: 0.1207, Accuracy: 95.66%\n",
      "Epoch [8/10], Step [1400/4501], Loss: 0.1245, Accuracy: 95.78%\n",
      "Epoch [8/10], Step [1500/4501], Loss: 0.1405, Accuracy: 95.34%\n",
      "Epoch [8/10], Step [1600/4501], Loss: 0.1175, Accuracy: 95.84%\n",
      "Epoch [8/10], Step [1700/4501], Loss: 0.1152, Accuracy: 95.94%\n",
      "Epoch [8/10], Step [1800/4501], Loss: 0.1175, Accuracy: 96.09%\n",
      "Epoch [8/10], Step [1900/4501], Loss: 0.1226, Accuracy: 95.62%\n",
      "Epoch [8/10], Step [2000/4501], Loss: 0.1284, Accuracy: 95.34%\n",
      "Epoch [8/10], Step [2100/4501], Loss: 0.1379, Accuracy: 95.25%\n",
      "Epoch [8/10], Step [2200/4501], Loss: 0.1182, Accuracy: 96.22%\n",
      "Epoch [8/10], Step [2300/4501], Loss: 0.1276, Accuracy: 94.94%\n",
      "Epoch [8/10], Step [2400/4501], Loss: 0.1374, Accuracy: 95.31%\n",
      "Epoch [8/10], Step [2500/4501], Loss: 0.1326, Accuracy: 95.22%\n",
      "Epoch [8/10], Step [2600/4501], Loss: 0.1359, Accuracy: 95.41%\n",
      "Epoch [8/10], Step [2700/4501], Loss: 0.1045, Accuracy: 96.09%\n",
      "Epoch [8/10], Step [2800/4501], Loss: 0.1141, Accuracy: 95.69%\n",
      "Epoch [8/10], Step [2900/4501], Loss: 0.1115, Accuracy: 96.00%\n",
      "Epoch [8/10], Step [3000/4501], Loss: 0.1349, Accuracy: 95.16%\n",
      "Epoch [8/10], Step [3100/4501], Loss: 0.1207, Accuracy: 95.97%\n",
      "Epoch [8/10], Step [3200/4501], Loss: 0.1318, Accuracy: 95.62%\n",
      "Epoch [8/10], Step [3300/4501], Loss: 0.1252, Accuracy: 95.19%\n",
      "Epoch [8/10], Step [3400/4501], Loss: 0.0971, Accuracy: 96.56%\n",
      "Epoch [8/10], Step [3500/4501], Loss: 0.1275, Accuracy: 95.81%\n",
      "Epoch [8/10], Step [3600/4501], Loss: 0.1083, Accuracy: 96.09%\n",
      "Epoch [8/10], Step [3700/4501], Loss: 0.1276, Accuracy: 95.66%\n",
      "Epoch [8/10], Step [3800/4501], Loss: 0.1399, Accuracy: 95.25%\n",
      "Epoch [8/10], Step [3900/4501], Loss: 0.1203, Accuracy: 96.03%\n",
      "Epoch [8/10], Step [4000/4501], Loss: 0.1352, Accuracy: 95.16%\n",
      "Epoch [8/10], Step [4100/4501], Loss: 0.1216, Accuracy: 95.66%\n",
      "Epoch [8/10], Step [4200/4501], Loss: 0.1240, Accuracy: 96.03%\n",
      "Epoch [8/10], Step [4300/4501], Loss: 0.1396, Accuracy: 95.38%\n",
      "Epoch [8/10], Step [4400/4501], Loss: 0.1241, Accuracy: 95.62%\n",
      "Epoch [8/10], Step [4500/4501], Loss: 0.1355, Accuracy: 95.41%\n",
      "Epoch [8/10], Val Loss: 40.8681, Val Accuracy: 95.52%\n",
      "Epoch [9/10], Step [100/4501], Loss: 0.1196, Accuracy: 95.88%\n",
      "Epoch [9/10], Step [200/4501], Loss: 0.1195, Accuracy: 95.69%\n",
      "Epoch [9/10], Step [300/4501], Loss: 0.1158, Accuracy: 96.09%\n",
      "Epoch [9/10], Step [400/4501], Loss: 0.1147, Accuracy: 95.81%\n",
      "Epoch [9/10], Step [500/4501], Loss: 0.1323, Accuracy: 95.16%\n",
      "Epoch [9/10], Step [600/4501], Loss: 0.1165, Accuracy: 95.81%\n",
      "Epoch [9/10], Step [700/4501], Loss: 0.1273, Accuracy: 95.62%\n",
      "Epoch [9/10], Step [800/4501], Loss: 0.1207, Accuracy: 95.53%\n",
      "Epoch [9/10], Step [900/4501], Loss: 0.1218, Accuracy: 95.91%\n",
      "Epoch [9/10], Step [1000/4501], Loss: 0.1167, Accuracy: 96.31%\n",
      "Epoch [9/10], Step [1100/4501], Loss: 0.1527, Accuracy: 94.66%\n",
      "Epoch [9/10], Step [1200/4501], Loss: 0.1251, Accuracy: 95.53%\n",
      "Epoch [9/10], Step [1300/4501], Loss: 0.1337, Accuracy: 95.50%\n",
      "Epoch [9/10], Step [1400/4501], Loss: 0.1105, Accuracy: 96.22%\n",
      "Epoch [9/10], Step [1500/4501], Loss: 0.1462, Accuracy: 94.62%\n",
      "Epoch [9/10], Step [1600/4501], Loss: 0.1315, Accuracy: 95.69%\n",
      "Epoch [9/10], Step [1700/4501], Loss: 0.1308, Accuracy: 95.66%\n",
      "Epoch [9/10], Step [1800/4501], Loss: 0.1236, Accuracy: 95.69%\n",
      "Epoch [9/10], Step [1900/4501], Loss: 0.1162, Accuracy: 95.81%\n",
      "Epoch [9/10], Step [2000/4501], Loss: 0.1293, Accuracy: 95.75%\n",
      "Epoch [9/10], Step [2100/4501], Loss: 0.1277, Accuracy: 95.66%\n",
      "Epoch [9/10], Step [2200/4501], Loss: 0.1181, Accuracy: 96.16%\n",
      "Epoch [9/10], Step [2300/4501], Loss: 0.1223, Accuracy: 95.47%\n",
      "Epoch [9/10], Step [2400/4501], Loss: 0.1087, Accuracy: 96.06%\n",
      "Epoch [9/10], Step [2500/4501], Loss: 0.1227, Accuracy: 95.66%\n",
      "Epoch [9/10], Step [2600/4501], Loss: 0.1348, Accuracy: 95.88%\n",
      "Epoch [9/10], Step [2700/4501], Loss: 0.1125, Accuracy: 96.16%\n",
      "Epoch [9/10], Step [2800/4501], Loss: 0.1345, Accuracy: 94.97%\n",
      "Epoch [9/10], Step [2900/4501], Loss: 0.1208, Accuracy: 95.78%\n",
      "Epoch [9/10], Step [3000/4501], Loss: 0.1296, Accuracy: 95.56%\n",
      "Epoch [9/10], Step [3100/4501], Loss: 0.1293, Accuracy: 95.91%\n",
      "Epoch [9/10], Step [3200/4501], Loss: 0.1124, Accuracy: 95.94%\n",
      "Epoch [9/10], Step [3300/4501], Loss: 0.1179, Accuracy: 95.91%\n",
      "Epoch [9/10], Step [3400/4501], Loss: 0.1141, Accuracy: 96.00%\n",
      "Epoch [9/10], Step [3500/4501], Loss: 0.1319, Accuracy: 95.53%\n",
      "Epoch [9/10], Step [3600/4501], Loss: 0.1224, Accuracy: 95.94%\n",
      "Epoch [9/10], Step [3700/4501], Loss: 0.1368, Accuracy: 95.12%\n",
      "Epoch [9/10], Step [3800/4501], Loss: 0.1206, Accuracy: 95.72%\n",
      "Epoch [9/10], Step [3900/4501], Loss: 0.1210, Accuracy: 95.78%\n",
      "Epoch [9/10], Step [4000/4501], Loss: 0.1209, Accuracy: 95.84%\n",
      "Epoch [9/10], Step [4100/4501], Loss: 0.1005, Accuracy: 96.41%\n",
      "Epoch [9/10], Step [4200/4501], Loss: 0.1035, Accuracy: 95.97%\n",
      "Epoch [9/10], Step [4300/4501], Loss: 0.1361, Accuracy: 95.06%\n",
      "Epoch [9/10], Step [4400/4501], Loss: 0.1134, Accuracy: 96.00%\n",
      "Epoch [9/10], Step [4500/4501], Loss: 0.1196, Accuracy: 95.38%\n",
      "Epoch [9/10], Val Loss: 475.0438, Val Accuracy: 93.20%\n",
      "Epoch [10/10], Step [100/4501], Loss: 0.1091, Accuracy: 96.16%\n",
      "Epoch [10/10], Step [200/4501], Loss: 0.1456, Accuracy: 94.94%\n",
      "Epoch [10/10], Step [300/4501], Loss: 0.1086, Accuracy: 96.25%\n",
      "Epoch [10/10], Step [400/4501], Loss: 0.1199, Accuracy: 95.59%\n",
      "Epoch [10/10], Step [500/4501], Loss: 0.1286, Accuracy: 95.53%\n",
      "Epoch [10/10], Step [600/4501], Loss: 0.1257, Accuracy: 95.97%\n",
      "Epoch [10/10], Step [700/4501], Loss: 0.1194, Accuracy: 96.06%\n",
      "Epoch [10/10], Step [800/4501], Loss: 0.1211, Accuracy: 95.50%\n",
      "Epoch [10/10], Step [900/4501], Loss: 0.1237, Accuracy: 95.66%\n",
      "Epoch [10/10], Step [1000/4501], Loss: 0.1175, Accuracy: 95.84%\n",
      "Epoch [10/10], Step [1100/4501], Loss: 0.1316, Accuracy: 95.16%\n",
      "Epoch [10/10], Step [1200/4501], Loss: 0.1204, Accuracy: 95.69%\n",
      "Epoch [10/10], Step [1300/4501], Loss: 0.1223, Accuracy: 95.69%\n",
      "Epoch [10/10], Step [1400/4501], Loss: 0.1264, Accuracy: 95.91%\n",
      "Epoch [10/10], Step [1500/4501], Loss: 0.1255, Accuracy: 96.09%\n",
      "Epoch [10/10], Step [1600/4501], Loss: 0.1365, Accuracy: 95.56%\n",
      "Epoch [10/10], Step [1700/4501], Loss: 0.1406, Accuracy: 95.22%\n",
      "Epoch [10/10], Step [1800/4501], Loss: 0.1260, Accuracy: 95.88%\n",
      "Epoch [10/10], Step [1900/4501], Loss: 0.1236, Accuracy: 95.69%\n",
      "Epoch [10/10], Step [2000/4501], Loss: 0.1210, Accuracy: 95.62%\n",
      "Epoch [10/10], Step [2100/4501], Loss: 0.1091, Accuracy: 96.56%\n",
      "Epoch [10/10], Step [2200/4501], Loss: 0.1164, Accuracy: 96.25%\n",
      "Epoch [10/10], Step [2300/4501], Loss: 0.1252, Accuracy: 95.94%\n",
      "Epoch [10/10], Step [2400/4501], Loss: 0.1212, Accuracy: 95.59%\n",
      "Epoch [10/10], Step [2500/4501], Loss: 0.1324, Accuracy: 95.34%\n",
      "Epoch [10/10], Step [2600/4501], Loss: 0.1325, Accuracy: 95.44%\n",
      "Epoch [10/10], Step [2700/4501], Loss: 0.1119, Accuracy: 95.81%\n",
      "Epoch [10/10], Step [2800/4501], Loss: 0.1247, Accuracy: 95.66%\n",
      "Epoch [10/10], Step [2900/4501], Loss: 0.1126, Accuracy: 96.25%\n",
      "Epoch [10/10], Step [3000/4501], Loss: 0.1059, Accuracy: 96.34%\n",
      "Epoch [10/10], Step [3100/4501], Loss: 0.1216, Accuracy: 96.06%\n",
      "Epoch [10/10], Step [3200/4501], Loss: 0.1293, Accuracy: 95.31%\n",
      "Epoch [10/10], Step [3300/4501], Loss: 0.1288, Accuracy: 95.31%\n",
      "Epoch [10/10], Step [3400/4501], Loss: 0.1090, Accuracy: 95.84%\n",
      "Epoch [10/10], Step [3500/4501], Loss: 0.1271, Accuracy: 95.72%\n",
      "Epoch [10/10], Step [3600/4501], Loss: 0.1231, Accuracy: 96.00%\n",
      "Epoch [10/10], Step [3700/4501], Loss: 0.1211, Accuracy: 96.12%\n",
      "Epoch [10/10], Step [3800/4501], Loss: 0.1271, Accuracy: 95.59%\n",
      "Epoch [10/10], Step [3900/4501], Loss: 0.1224, Accuracy: 95.88%\n",
      "Epoch [10/10], Step [4000/4501], Loss: 0.1150, Accuracy: 95.81%\n",
      "Epoch [10/10], Step [4100/4501], Loss: 0.1196, Accuracy: 95.75%\n",
      "Epoch [10/10], Step [4200/4501], Loss: 0.1157, Accuracy: 95.81%\n",
      "Epoch [10/10], Step [4300/4501], Loss: 0.1339, Accuracy: 95.44%\n",
      "Epoch [10/10], Step [4400/4501], Loss: 0.1169, Accuracy: 95.97%\n",
      "Epoch [10/10], Step [4500/4501], Loss: 0.1295, Accuracy: 95.44%\n",
      "Epoch [10/10], Val Loss: 6.6647, Val Accuracy: 96.04%\n"
     ]
    }
   ],
   "source": [
    "experiment.train_model(model, train_data, val_data, criterion, optimizer, num_epochs= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('user_tower.0.weight',\n",
       "              tensor([[ 2.0844e-02,  1.3165e+00,  5.4387e-03,  ...,  4.0862e-02,\n",
       "                        2.0535e+00, -1.7014e-02],\n",
       "                      [-6.5881e-04, -2.7121e-01, -1.2417e-02,  ..., -2.0120e-01,\n",
       "                       -1.3770e-01, -8.5330e-02],\n",
       "                      [ 2.4239e-01, -4.2425e-01, -2.9521e-02,  ..., -3.4112e-01,\n",
       "                        2.5986e-01, -1.9391e-02],\n",
       "                      ...,\n",
       "                      [ 3.0320e-02,  1.0299e+00,  1.1620e-01,  ...,  7.5602e-02,\n",
       "                        1.2858e+00, -5.2581e-01],\n",
       "                      [ 1.1721e-01, -4.8162e-02, -2.3207e-01,  ...,  7.8701e-01,\n",
       "                        1.6706e+00, -1.3500e-02],\n",
       "                      [-1.5046e-02, -1.0051e+00, -9.2982e-02,  ..., -7.9323e-02,\n",
       "                        8.6616e-01, -5.1195e-02]], device='mps:0')),\n",
       "             ('user_tower.0.bias',\n",
       "              tensor([ 1.4880,  0.1070,  0.2881,  0.4717,  0.3966,  0.3893,  0.2597,  1.0146,\n",
       "                      -0.4239, -0.2222,  1.4684,  0.9075,  0.4498,  0.4703,  0.6974,  0.4623,\n",
       "                       0.0165,  0.9377, -0.5449,  0.3026,  0.2793,  0.2821,  0.0587,  1.7372,\n",
       "                       0.8012,  1.0738, -0.5273,  1.7075, -0.2402,  1.8837,  1.6200,  0.3657,\n",
       "                      -0.1501,  1.2774, -0.6704, -0.2878, -0.5699,  1.3311,  0.3496, -0.9817,\n",
       "                      -0.1753,  1.0195,  0.1156,  0.2323, -0.5119,  0.1790, -0.0865, -0.3193,\n",
       "                       1.5405,  0.3805,  0.5153, -0.1240, -0.2402,  0.2132,  0.6085,  0.7676,\n",
       "                      -0.0512, -0.0080, -0.0513,  0.8979,  0.6153,  0.6192,  0.4497,  0.5200,\n",
       "                       0.8168, -0.1863,  0.5679,  0.2749, -0.0919,  0.8055,  0.2298,  0.8066,\n",
       "                       0.1042, -0.1352, -0.3461,  1.1067,  0.3873, -0.2007,  0.4748,  0.1288,\n",
       "                       0.6169, -0.4483, -0.5714,  0.2202, -0.3594,  0.3448,  1.8879,  0.0071,\n",
       "                      -0.4031,  0.0805,  0.8671,  0.9613,  2.7165,  0.3650, -0.1207,  0.2887,\n",
       "                      -0.7001,  1.7119,  1.2933, -0.0302, -0.7158,  0.2920,  0.4550,  1.1463,\n",
       "                      -0.0690,  1.0131, -0.0984,  0.1012,  0.0254, -0.2781, -1.0334, -0.2259,\n",
       "                       1.2591,  1.1169,  0.3091,  0.9126,  0.1273,  0.5779, -0.4977, -0.1491,\n",
       "                       1.2179,  0.7800, -0.0976,  0.6489,  0.5960,  1.6826, -0.1983, -0.0422,\n",
       "                      -0.3072,  0.5746,  1.6066, -0.0948,  0.9666,  0.1989, -0.1934,  1.7520,\n",
       "                       0.0853,  0.0445,  0.3483, -0.2245, -0.5801,  0.1145,  0.5731,  0.2171,\n",
       "                       0.3887,  0.5210,  0.4677, -0.7451,  0.6854, -0.1813,  0.3751,  0.2355,\n",
       "                       1.3290,  0.3109,  1.3923, -0.1113,  0.0816,  0.8276, -0.2940,  0.6498,\n",
       "                       0.0718,  0.9132,  0.1438,  0.2062,  0.1926,  0.8921, -0.2876,  0.0688,\n",
       "                       0.5735,  0.0061,  1.0544,  0.7726,  0.7877, -0.3493,  0.3080,  1.1048,\n",
       "                      -0.2564,  1.5352, -0.0467,  0.7309,  1.0869,  0.1805,  0.1837,  0.3568,\n",
       "                      -0.0581,  0.1366, -0.6170,  0.4145, -0.3753,  0.0517, -0.1867,  1.8964,\n",
       "                       0.2519,  0.7521,  0.6479,  0.4516, -0.3108,  0.3725,  0.2437, -1.0424,\n",
       "                      -0.6152,  0.6039,  0.4388,  0.9238,  0.6054,  0.1475,  0.1118,  0.2212,\n",
       "                      -0.1553, -0.2237,  0.2787,  0.3325,  0.3224, -0.3642,  0.7844, -0.3732,\n",
       "                       0.3877,  0.7842,  0.0884,  1.4447,  0.5587,  0.1342,  0.4386,  0.5208,\n",
       "                       0.5351, -0.1124, -0.8060, -0.3312, -0.5580,  0.0852,  0.3375,  0.2786,\n",
       "                       0.5453,  0.3062, -0.4964,  0.1446,  0.1922, -0.1662,  0.1071, -0.4849,\n",
       "                       1.0939,  2.0620,  0.3527, -0.3844, -0.6656,  0.4781,  0.7910, -0.1137,\n",
       "                       0.0732, -0.0902,  0.5759, -0.5278,  0.5127,  0.6643, -0.2268,  1.9541],\n",
       "                     device='mps:0')),\n",
       "             ('user_tower.2.weight',\n",
       "              tensor([0.9553, 1.0111, 0.2271, 0.5018, 1.0551, 0.6091, 0.6130, 0.7181, 0.6225,\n",
       "                      1.0096, 0.7413, 1.3066, 0.6115, 0.6945, 0.9141, 0.7259, 1.1106, 0.2563,\n",
       "                      0.7061, 0.5049, 0.9081, 0.3295, 1.4043, 1.2820, 0.7990, 0.9118, 0.5404,\n",
       "                      0.9783, 0.6016, 1.4202, 0.9128, 1.0332, 1.0024, 1.2784, 0.9740, 1.0000,\n",
       "                      0.8954, 1.5100, 0.8319, 1.2374, 1.0000, 0.8946, 1.0933, 0.3021, 0.9129,\n",
       "                      1.0212, 0.6004, 0.7055, 1.0311, 0.2477, 0.7326, 0.4655, 0.4636, 0.6841,\n",
       "                      0.5162, 0.6469, 1.1968, 0.3803, 0.7663, 0.4418, 1.1757, 1.0362, 0.3231,\n",
       "                      1.1075, 1.3860, 0.6722, 0.6125, 0.8315, 0.7006, 1.1275, 1.0000, 0.9611,\n",
       "                      0.9996, 0.8377, 0.4960, 0.9624, 0.5719, 0.7807, 0.4846, 0.3969, 1.0331,\n",
       "                      0.2489, 0.8574, 0.4795, 0.6536, 1.0333, 1.0781, 0.8312, 1.0219, 0.7678,\n",
       "                      0.5930, 0.5850, 1.3475, 1.0382, 1.0000, 1.0000, 0.5957, 1.1027, 1.0386,\n",
       "                      1.0567, 0.6347, 0.6607, 0.6411, 0.8085, 0.6534, 1.2792, 0.8964, 0.7399,\n",
       "                      0.8282, 0.9280, 1.0979, 0.4649, 0.9355, 1.1466, 1.1238, 0.8653, 1.0564,\n",
       "                      1.1104, 0.7452, 0.7148, 1.2927, 1.1605, 0.8928, 1.1252, 0.5564, 1.2647,\n",
       "                      0.3079, 0.9873, 1.0890, 1.0461, 0.8552, 0.5314, 0.5042, 1.0000, 1.2155,\n",
       "                      0.9619, 1.0498, 1.0000, 1.0000, 0.9038, 0.7476, 1.1940, 0.6685, 0.3711,\n",
       "                      0.5176, 0.9799, 0.7166, 0.6047, 0.6097, 0.8324, 1.0000, 1.2782, 0.9305,\n",
       "                      1.0243, 1.0053, 1.0322, 0.6057, 1.1864, 0.6532, 0.7107, 1.1825, 0.6879,\n",
       "                      0.7109, 0.5286, 1.0091, 0.5906, 0.9589, 1.0426, 1.1107, 0.3978, 1.1759,\n",
       "                      1.2115, 0.8333, 1.1050, 0.6492, 1.2263, 1.0000, 0.7086, 0.6028, 0.6917,\n",
       "                      0.9175, 0.5719, 0.7053, 0.7882, 0.4486, 1.0832, 0.6311, 0.5451, 0.9394,\n",
       "                      0.4441, 0.4060, 1.6805, 1.0679, 0.7637, 1.1041, 0.8283, 0.6007, 1.0885,\n",
       "                      0.6793, 0.7228, 1.2087, 0.4369, 0.9112, 0.8590, 1.0899, 1.0708, 0.6809,\n",
       "                      1.0445, 0.4931, 0.5116, 0.3381, 0.4417, 0.5737, 0.9792, 0.8445, 0.6296,\n",
       "                      1.0279, 0.8876, 0.8229, 0.7565, 1.0431, 1.0605, 0.9626, 0.6959, 0.5564,\n",
       "                      1.0552, 0.6677, 1.0000, 1.4059, 0.6953, 1.0000, 0.6185, 0.2168, 0.3966,\n",
       "                      0.5568, 0.3850, 1.0918, 1.0260, 1.1180, 0.9391, 1.2276, 1.3027, 1.0000,\n",
       "                      0.6932, 1.1124, 0.4166, 1.3046, 1.1872, 1.1288, 0.8164, 0.7451, 0.4710,\n",
       "                      0.7527, 0.6026, 0.5761, 1.0362], device='mps:0')),\n",
       "             ('user_tower.2.bias',\n",
       "              tensor([ 0.3165, -0.1012,  0.0052,  0.2884, -0.2697,  0.3241,  0.3360,  0.4411,\n",
       "                       0.4309,  0.0484,  0.4768, -0.0756,  0.1868,  0.3512,  0.2871,  0.1869,\n",
       "                      -0.0834,  0.3730,  0.3117,  0.4323,  0.0679,  0.2670,  0.2079, -0.0630,\n",
       "                       0.3177,  0.3922,  0.1805,  0.3447,  0.2131, -0.0752,  0.2995,  0.2927,\n",
       "                       0.2171, -0.0052,  0.0575, -0.0850, -0.0378, -0.0068,  0.1289,  0.1152,\n",
       "                       0.2800,  0.3167,  0.0511,  0.0179, -0.0968, -0.0012,  0.2412,  0.4565,\n",
       "                       0.3808,  0.3861,  0.3022,  0.1419,  0.4048,  0.2860,  0.2371,  0.3685,\n",
       "                       0.1407,  0.1660,  0.5358,  0.2962, -0.0534,  0.0693,  0.3466,  0.4358,\n",
       "                      -0.0790, -0.1075,  0.2114,  0.4085,  0.3743,  0.1970, -0.3195,  0.3291,\n",
       "                       0.0242,  0.1305,  0.2865,  0.4126,  0.0389,  0.2503,  0.3344,  0.2338,\n",
       "                      -0.1734,  0.1771, -0.0514,  0.2556,  0.3924, -0.1481,  0.1833, -0.0267,\n",
       "                      -0.0846,  0.0750,  0.2822,  0.3403,  0.2089, -0.0591, -0.3283,  0.1423,\n",
       "                       0.1819,  0.4200,  0.4056,  0.1799, -0.1394,  0.1568,  0.3767,  0.2891,\n",
       "                       0.1827, -0.0334,  0.1793,  0.0406,  0.2727, -0.0643, -0.1926,  0.1685,\n",
       "                       0.1975,  0.0247,  0.0881,  0.3114, -0.1401,  0.0790,  0.2841, -0.1160,\n",
       "                      -0.0405,  0.0006,  0.0227, -0.1738,  0.2664, -0.0149, -0.0626,  0.0384,\n",
       "                       0.0674, -0.1255,  0.3143,  0.2123,  0.4183,  0.2423,  0.0224,  0.4726,\n",
       "                       0.3519, -0.3783, -0.3408,  0.2754, -0.2061, -0.0599,  0.2789,  0.2590,\n",
       "                       0.2602, -0.0916,  0.4109,  0.2788,  0.3828,  0.2505, -0.2680, -0.0714,\n",
       "                       0.3144, -0.0365,  0.3856,  0.2463,  0.1495, -0.0485,  0.2381,  0.2788,\n",
       "                       0.0586,  0.3116,  0.1458,  0.2748,  0.0371,  0.2562, -0.1112, -0.2030,\n",
       "                      -0.0591,  0.1437,  0.3795, -0.0653,  0.2864,  0.3493,  0.4062, -0.1534,\n",
       "                      -0.3496,  0.1979,  0.3987,  0.2579,  0.2610,  0.1739,  0.1349, -0.2065,\n",
       "                       0.3403, -0.0948,  0.1520, -0.0078,  0.1452,  0.1847,  0.0519, -0.3612,\n",
       "                      -0.0148,  0.2769, -0.0377,  0.0144,  0.1658, -0.1073,  0.2935,  0.4590,\n",
       "                      -0.0354,  0.3494,  0.1305,  0.2974, -0.0713, -0.0354,  0.1473,  0.0693,\n",
       "                      -0.0140,  0.4086,  0.3869,  0.3793,  0.4167, -0.0900,  0.4075,  0.2011,\n",
       "                       0.0381,  0.1133,  0.4888,  0.2809, -0.0059, -0.0893,  0.3811,  0.3428,\n",
       "                       0.0409, -0.1243, -0.0138, -0.2293,  0.1082,  0.3709,  0.2019,  0.0100,\n",
       "                       0.0347,  0.2258,  0.2774,  0.0138, -0.1428,  0.0152,  0.1665,  0.4672,\n",
       "                       0.3839, -0.0616,  0.1136,  0.2991,  0.1109,  0.2716, -0.0916,  0.2784,\n",
       "                       0.0459,  0.1701,  0.2629,  0.2876,  0.3036,  0.2067,  0.4570,  0.0864],\n",
       "                     device='mps:0')),\n",
       "             ('user_tower.2.running_mean',\n",
       "              tensor([4.5791e+02, 0.0000e+00, 1.3312e+02, 4.2702e+02, 0.0000e+00, 4.5280e+00,\n",
       "                      1.3907e+02, 3.6657e+02, 2.0929e+02, 8.1046e-01, 1.6734e+02, 0.0000e+00,\n",
       "                      1.0575e+02, 2.0916e+02, 4.0143e+02, 1.8528e+01, 0.0000e+00, 3.0060e+02,\n",
       "                      7.6748e+01, 5.0342e+02, 0.0000e+00, 5.7098e+02, 0.0000e+00, 0.0000e+00,\n",
       "                      3.4765e+02, 4.3585e+02, 8.2639e+01, 5.3813e+02, 5.8205e+01, 0.0000e+00,\n",
       "                      3.7176e+02, 1.2121e+02, 1.7214e+01, 0.0000e+00, 2.4353e+01, 0.0000e+00,\n",
       "                      5.0773e+01, 0.0000e+00, 1.1431e+02, 3.8337e+01, 0.0000e+00, 2.7797e+02,\n",
       "                      0.0000e+00, 1.0051e+02, 0.0000e+00, 0.0000e+00, 1.5961e+01, 2.0032e+02,\n",
       "                      5.6293e+02, 9.3649e+01, 4.1917e+02, 1.8816e+02, 7.2809e+02, 1.2898e+02,\n",
       "                      3.2713e+02, 3.7534e+02, 7.5476e+00, 1.3969e+02, 2.8512e+02, 4.5615e+02,\n",
       "                      0.0000e+00, 0.0000e+00, 1.6999e+02, 4.3407e+02, 0.0000e+00, 1.3672e+02,\n",
       "                      1.5577e+02, 1.9963e+02, 3.9984e+02, 0.0000e+00, 0.0000e+00, 4.5905e+02,\n",
       "                      0.0000e+00, 2.3581e+01, 5.3345e+02, 2.9615e+02, 0.0000e+00, 1.1191e+01,\n",
       "                      3.1982e+02, 3.2331e+02, 0.0000e+00, 9.5642e+01, 7.0201e+01, 2.6842e+02,\n",
       "                      5.5202e+02, 0.0000e+00, 2.6335e+00, 0.0000e+00, 0.0000e+00, 2.5171e+02,\n",
       "                      1.9096e+02, 1.7200e+02, 2.5478e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "                      2.4394e+02, 4.6280e+02, 5.1284e+02, 0.0000e+00, 3.0651e+02, 1.9383e+02,\n",
       "                      4.7842e+02, 3.7257e+02, 4.1912e+02, 0.0000e+00, 5.0470e+01, 3.4016e+01,\n",
       "                      5.6816e+01, 2.5970e+01, 5.0565e+01, 4.8566e+02, 3.8822e+02, 0.0000e+00,\n",
       "                      0.0000e+00, 5.1545e+02, 0.0000e+00, 8.3950e+00, 3.2412e+01, 0.0000e+00,\n",
       "                      0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4608e+02, 0.0000e+00,\n",
       "                      1.2121e+02, 0.0000e+00, 3.3596e+01, 0.0000e+00, 3.8934e+02, 6.9210e+01,\n",
       "                      3.8496e+02, 0.0000e+00, 4.1031e+01, 3.8690e+02, 2.1966e+02, 0.0000e+00,\n",
       "                      0.0000e+00, 0.0000e+00, 1.7152e+02, 0.0000e+00, 1.5365e+02, 1.5756e+02,\n",
       "                      4.0059e+02, 0.0000e+00, 1.7276e+02, 5.0082e+01, 1.5305e+02, 2.2961e+01,\n",
       "                      0.0000e+00, 0.0000e+00, 3.8149e+02, 0.0000e+00, 3.7704e+02, 1.5226e+01,\n",
       "                      6.4998e+01, 0.0000e+00, 1.6701e+01, 1.5452e+02, 0.0000e+00, 3.3725e+02,\n",
       "                      3.6813e+01, 5.5680e+02, 0.0000e+00, 3.7987e+02, 6.1435e+00, 0.0000e+00,\n",
       "                      0.0000e+00, 5.8521e+02, 5.6934e+02, 0.0000e+00, 3.1008e+02, 1.0164e+01,\n",
       "                      1.9677e+02, 0.0000e+00, 0.0000e+00, 4.4009e+02, 3.2191e+02, 4.7970e+02,\n",
       "                      2.8556e+02, 1.6404e+02, 1.5646e+02, 2.8232e+02, 1.3767e+02, 0.0000e+00,\n",
       "                      8.8287e+01, 2.9460e+02, 1.0636e+02, 4.0187e+02, 4.9466e+01, 0.0000e+00,\n",
       "                      6.8761e+01, 2.5243e+02, 0.0000e+00, 2.1092e+02, 6.1162e+01, 0.0000e+00,\n",
       "                      4.1782e+02, 1.3485e+02, 7.4060e+01, 4.3584e+02, 0.0000e+00, 1.9710e+02,\n",
       "                      0.0000e+00, 0.0000e+00, 4.7101e+01, 2.9588e+02, 3.1175e+02, 4.5691e+02,\n",
       "                      9.8129e+01, 2.7087e+02, 6.0942e+02, 2.0879e+01, 4.0334e+02, 2.3727e+02,\n",
       "                      0.0000e+00, 0.0000e+00, 2.7087e+02, 3.4469e+02, 1.3591e+00, 0.0000e+00,\n",
       "                      1.3566e+02, 1.2361e+02, 3.2046e+02, 0.0000e+00, 2.3841e+02, 0.0000e+00,\n",
       "                      1.2123e-01, 1.0430e+02, 0.0000e+00, 2.4142e+02, 1.7548e+02, 5.1003e+02,\n",
       "                      8.1127e+01, 1.4777e+02, 0.0000e+00, 0.0000e+00, 1.9689e+01, 2.0598e+02,\n",
       "                      3.8632e+02, 0.0000e+00, 0.0000e+00, 3.3303e+01, 6.1929e+01, 2.1266e+02,\n",
       "                      0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8523e-05, 2.7068e+02, 6.3291e+01,\n",
       "                      2.5527e+02, 4.4831e+02, 2.3326e+02, 0.0000e+00], device='mps:0')),\n",
       "             ('user_tower.2.running_var',\n",
       "              tensor([1.4159e+06, 0.0000e+00, 1.0432e+06, 2.9168e+06, 0.0000e+00, 1.7436e+03,\n",
       "                      1.8499e+04, 8.7780e+05, 9.7042e+04, 7.6520e+01, 1.4659e+05, 0.0000e+00,\n",
       "                      1.7469e+05, 6.0509e+04, 1.0508e+06, 3.8995e+03, 0.0000e+00, 2.5231e+06,\n",
       "                      9.2655e+04, 8.9985e+06, 0.0000e+00, 1.2841e+07, 0.0000e+00, 0.0000e+00,\n",
       "                      8.6819e+05, 1.5420e+06, 3.1863e+05, 2.1363e+06, 1.1391e+05, 0.0000e+00,\n",
       "                      1.0570e+06, 9.6435e+04, 8.6105e+03, 0.0000e+00, 1.3036e+04, 0.0000e+00,\n",
       "                      5.4236e+04, 0.0000e+00, 2.0017e+05, 3.3024e+04, 0.0000e+00, 6.3642e+05,\n",
       "                      0.0000e+00, 4.1741e+05, 0.0000e+00, 0.0000e+00, 1.3424e+04, 2.7365e+05,\n",
       "                      2.3415e+06, 9.0332e+04, 1.1915e+06, 1.8730e+06, 2.0260e+07, 8.6434e+05,\n",
       "                      7.5814e+05, 8.6437e+05, 1.7976e+03, 1.0265e+06, 6.1789e+04, 5.6803e+06,\n",
       "                      0.0000e+00, 0.0000e+00, 1.3740e+06, 1.5634e+06, 0.0000e+00, 2.5084e+05,\n",
       "                      1.3897e+05, 2.0116e+05, 6.8217e+06, 0.0000e+00, 0.0000e+00, 1.3177e+06,\n",
       "                      0.0000e+00, 1.8253e+04, 1.1909e+07, 6.8697e+05, 0.0000e+00, 1.7764e+04,\n",
       "                      3.3819e+06, 3.7054e+06, 0.0000e+00, 5.3492e+05, 8.2268e+04, 1.5808e+06,\n",
       "                      1.3837e+07, 0.0000e+00, 2.3983e+01, 0.0000e+00, 0.0000e+00, 9.7406e+05,\n",
       "                      2.6273e+05, 2.3052e+05, 1.5388e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "                      8.4427e+05, 1.3736e+06, 1.7583e+06, 0.0000e+00, 1.8476e+06, 2.1986e+06,\n",
       "                      3.0442e+06, 1.0600e+06, 6.5834e+06, 0.0000e+00, 1.9589e+04, 2.8762e+04,\n",
       "                      6.9767e+04, 1.6669e+04, 5.1006e+04, 9.1347e+06, 7.8991e+05, 0.0000e+00,\n",
       "                      0.0000e+00, 1.7090e+06, 0.0000e+00, 3.5888e+02, 2.8859e+04, 0.0000e+00,\n",
       "                      0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8030e+05, 0.0000e+00,\n",
       "                      7.0115e+05, 0.0000e+00, 2.6756e+04, 0.0000e+00, 1.1238e+06, 8.1138e+04,\n",
       "                      4.8421e+06, 0.0000e+00, 2.6964e+04, 1.0721e+06, 3.8345e+05, 0.0000e+00,\n",
       "                      0.0000e+00, 0.0000e+00, 4.7982e+05, 0.0000e+00, 8.2064e+05, 1.9736e+05,\n",
       "                      1.2726e+06, 0.0000e+00, 5.3135e+04, 1.0381e+05, 3.2466e+05, 1.5532e+04,\n",
       "                      0.0000e+00, 0.0000e+00, 1.0959e+06, 0.0000e+00, 1.0737e+06, 5.1009e+03,\n",
       "                      7.3672e+04, 0.0000e+00, 1.4773e+04, 1.7785e+05, 0.0000e+00, 7.2516e+05,\n",
       "                      4.2249e+03, 1.3431e+07, 0.0000e+00, 1.5916e+06, 1.6019e+03, 0.0000e+00,\n",
       "                      0.0000e+00, 1.2395e+07, 2.1939e+06, 0.0000e+00, 7.9221e+05, 1.0656e+04,\n",
       "                      1.0481e+05, 0.0000e+00, 0.0000e+00, 5.4891e+06, 2.6278e+05, 1.6367e+06,\n",
       "                      5.9884e+05, 1.9563e+05, 2.1884e+04, 1.1407e+06, 2.1401e+05, 0.0000e+00,\n",
       "                      1.0619e+05, 3.4793e+06, 2.6447e+05, 2.1393e+06, 5.5834e+04, 0.0000e+00,\n",
       "                      5.5454e+04, 1.0468e+06, 0.0000e+00, 4.5139e+05, 4.1534e+04, 0.0000e+00,\n",
       "                      1.1730e+06, 7.7762e+04, 9.4412e+04, 7.7931e+06, 0.0000e+00, 2.9611e+05,\n",
       "                      0.0000e+00, 0.0000e+00, 8.1233e+04, 6.5190e+05, 4.2521e+06, 8.3965e+06,\n",
       "                      1.0079e+05, 2.0943e+06, 1.4463e+07, 1.2587e+04, 1.1947e+06, 2.0155e+06,\n",
       "                      0.0000e+00, 0.0000e+00, 5.0007e+04, 8.6775e+05, 6.0685e+00, 0.0000e+00,\n",
       "                      1.1194e+05, 2.8419e+04, 5.4681e+06, 0.0000e+00, 2.1626e+06, 0.0000e+00,\n",
       "                      2.5992e+00, 8.8726e+04, 0.0000e+00, 3.0466e+06, 8.0753e+05, 5.1688e+06,\n",
       "                      3.4488e+05, 1.1978e+06, 0.0000e+00, 0.0000e+00, 9.0469e+03, 3.2542e+04,\n",
       "                      1.2251e+06, 0.0000e+00, 0.0000e+00, 2.4572e+04, 6.3638e+04, 1.1368e+06,\n",
       "                      0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8660e-03, 5.6825e+05, 1.0275e+05,\n",
       "                      5.1703e+05, 1.3635e+06, 6.0728e+04, 0.0000e+00], device='mps:0')),\n",
       "             ('user_tower.2.num_batches_tracked',\n",
       "              tensor(45010, device='mps:0')),\n",
       "             ('user_tower.4.weight',\n",
       "              tensor([[ 0.1241,  0.0961,  0.0932,  ...,  0.1910,  0.1868, -0.1286],\n",
       "                      [ 0.3418,  0.2326,  0.0439,  ..., -0.0070,  0.0491, -0.0566],\n",
       "                      [ 0.1858,  0.1075,  0.0756,  ...,  0.4737, -0.0078,  0.1357],\n",
       "                      ...,\n",
       "                      [ 0.2968,  0.1475,  0.0099,  ...,  0.1072, -0.1661, -0.2081],\n",
       "                      [ 0.0795,  0.2601, -0.2136,  ...,  0.0539, -0.0310,  0.2087],\n",
       "                      [ 0.0099,  0.3138, -0.0123,  ..., -0.0905, -0.3244,  0.1098]],\n",
       "                     device='mps:0')),\n",
       "             ('user_tower.4.bias',\n",
       "              tensor([ 0.1056, -0.5773, -0.3305, -0.0028, -0.2969,  0.2220,  0.1652, -0.2084,\n",
       "                       0.0167, -0.0321, -0.2877, -0.0037,  0.0492,  0.1891, -0.0023, -0.1232,\n",
       "                      -0.1693,  0.0386, -0.6517, -0.0593,  0.0019,  0.0419,  0.0083,  0.3524,\n",
       "                       0.0409, -0.1749, -0.0454,  0.1963, -0.3012, -0.0044, -0.2945,  0.1023,\n",
       "                      -0.1154, -0.2089, -0.3047, -0.2908, -0.0250, -0.5765, -0.2109,  0.0619,\n",
       "                      -0.6729, -0.2756, -0.6521,  0.4160, -0.7573, -0.1027, -0.2183, -0.0229,\n",
       "                      -0.4219,  0.4630, -0.3279, -0.5067,  0.3934, -0.2400,  0.6142, -0.5705,\n",
       "                      -0.0893,  0.5926,  0.0669, -0.1527,  0.3254, -0.5505, -0.5928,  0.2425,\n",
       "                      -0.0516, -0.1037, -0.0177, -0.3351,  0.0068, -0.2233, -0.0484, -0.1549,\n",
       "                      -0.0419, -0.1079, -0.0781, -0.1327, -0.0865, -0.3762,  0.6842, -0.3888,\n",
       "                      -0.6188,  0.0876,  0.1050, -0.4943, -0.0756, -0.0241,  0.0493, -0.3861,\n",
       "                       0.8860, -0.0178, -0.0105, -0.2846,  0.0232, -0.1883, -0.4772,  0.1768,\n",
       "                      -0.4730, -0.0646, -0.1376,  0.0334, -0.0898,  0.0886, -0.0139, -0.2406,\n",
       "                       0.6093, -0.2243,  0.6065,  0.1179, -0.0603, -0.0861, -0.0205, -0.2865,\n",
       "                      -0.7519, -0.0567,  0.0195, -0.5508,  0.9484,  0.0616,  0.8839, -0.5802,\n",
       "                      -0.1226, -0.2515, -0.5001, -0.1794, -0.0954, -0.0406, -0.4934, -0.3392],\n",
       "                     device='mps:0')),\n",
       "             ('user_tower.6.weight',\n",
       "              tensor([0.8394, 0.9586, 0.5577, 0.7627, 1.0990, 0.9485, 0.7502, 0.8119, 1.0969,\n",
       "                      0.8064, 0.9485, 0.7117, 1.0841, 0.9042, 0.8008, 0.5644, 1.6197, 0.4554,\n",
       "                      0.9055, 1.0203, 0.5674, 0.8428, 1.1500, 0.8876, 1.2224, 0.8614, 0.9566,\n",
       "                      0.9578, 1.0799, 0.5790, 0.6130, 0.9595, 1.0282, 1.5362, 1.0864, 1.0499,\n",
       "                      1.0545, 1.2665, 0.8448, 1.1224, 1.0752, 1.4032, 1.1936, 0.8224, 0.9696,\n",
       "                      1.6365, 1.1555, 1.0455, 0.9725, 0.8883, 1.0389, 0.9708, 1.0065, 1.5811,\n",
       "                      0.9478, 0.5566, 1.2991, 0.8225, 1.3190, 0.4929, 1.0963, 1.0900, 1.1699,\n",
       "                      1.0028, 0.7565, 0.4889, 0.8620, 1.1951, 0.7060, 1.5592, 0.8972, 1.1486,\n",
       "                      1.0432, 1.1578, 1.1229, 1.0062, 1.1252, 1.0760, 0.9761, 0.9220, 1.1664,\n",
       "                      1.1370, 1.0312, 0.9699, 0.9991, 0.9356, 1.1120, 1.5199, 1.0514, 0.7908,\n",
       "                      0.7969, 0.5732, 1.1458, 0.7306, 0.7780, 0.2927, 1.0874, 0.9408, 1.1619,\n",
       "                      0.7310, 0.9729, 0.6189, 0.8851, 0.8906, 0.7809, 1.4114, 0.6732, 0.7306,\n",
       "                      1.2496, 1.1187, 0.7256, 1.2862, 0.9061, 1.0666, 1.0473, 1.0280, 0.8676,\n",
       "                      1.2438, 0.9479, 1.0922, 1.0079, 1.0079, 1.2501, 0.9680, 0.8988, 0.4911,\n",
       "                      1.0483, 0.3658], device='mps:0')),\n",
       "             ('user_tower.6.bias',\n",
       "              tensor([ 0.2272,  0.3721,  0.3201,  0.1866,  0.1261, -0.2581,  0.0631, -0.0532,\n",
       "                       0.2091,  0.1696,  0.2912,  0.3091,  0.3195, -0.1822,  0.1393,  0.0792,\n",
       "                       0.1129,  0.2235,  0.2081,  0.0537,  0.0444,  0.0801,  0.2062, -0.2720,\n",
       "                       0.1498,  0.0603,  0.2377, -0.0593,  0.1154,  0.2536,  0.0435, -0.0099,\n",
       "                      -0.0713,  0.1477,  0.1310,  0.0946,  0.3861,  0.0844,  0.0316,  0.1203,\n",
       "                       0.1669,  0.1829,  0.1855, -0.3404,  0.1975,  0.0851,  0.2553,  0.1073,\n",
       "                       0.1575, -0.2467,  0.0764,  0.0094, -0.1180,  0.2109, -0.0283,  0.3173,\n",
       "                       0.4191, -0.0135,  0.4767,  0.0420, -0.2144,  0.2452,  0.2442, -0.1948,\n",
       "                       0.2057,  0.2323,  0.3827,  0.2366,  0.0532,  0.2371,  0.1068,  0.1439,\n",
       "                       0.0541, -0.0082,  0.3097, -0.0266, -0.0254,  0.1811, -0.1384, -0.0102,\n",
       "                       0.0940,  0.1587,  0.5400,  0.2165,  0.0724,  0.0626,  0.4686,  0.0202,\n",
       "                      -0.0641,  0.2650,  0.0401,  0.1137,  0.0941,  0.2423,  0.1600,  0.0082,\n",
       "                       0.0165, -0.0832,  0.1126,  0.1810,  0.0356,  0.2002, -0.0276,  0.1021,\n",
       "                      -0.3859,  0.1918, -0.2625, -0.2848,  0.1629,  0.2192,  0.4030,  0.0194,\n",
       "                       0.2324,  0.3416,  0.3468,  0.1021, -0.0916,  0.4304, -0.2629,  0.0514,\n",
       "                       0.1428,  0.0175,  0.3937, -0.0267,  0.4188,  0.1333,  0.2974,  0.1599],\n",
       "                     device='mps:0')),\n",
       "             ('user_tower.6.running_mean',\n",
       "              tensor([2.0105e+00, 1.3717e+00, 4.2142e+00, 2.4270e+00, 2.8147e+00, 4.0768e+00,\n",
       "                      3.7948e+00, 7.5261e-01, 5.0739e+00, 1.6963e+00, 1.6364e-01, 4.5564e+00,\n",
       "                      3.6019e+00, 1.1558e+00, 9.3380e-01, 2.3464e+00, 0.0000e+00, 1.3655e+00,\n",
       "                      1.5843e-01, 4.2808e+00, 3.7427e+00, 1.1407e+00, 3.1207e+00, 2.5348e+00,\n",
       "                      4.7685e+00, 1.2707e+00, 3.4253e+00, 1.8306e+00, 4.0616e+00, 3.7655e+00,\n",
       "                      1.6096e+00, 1.0765e+00, 3.2202e-01, 2.0142e-01, 3.1352e+00, 7.7991e-01,\n",
       "                      5.0469e+00, 0.0000e+00, 3.5434e+00, 3.1224e+00, 9.3696e-01, 1.6080e-02,\n",
       "                      8.4177e-02, 2.6041e+00, 7.3416e-01, 3.3905e-13, 6.9782e-01, 3.3897e+00,\n",
       "                      1.2327e+00, 2.7418e+00, 2.5764e+00, 1.6905e+00, 1.0455e+00, 2.2680e-18,\n",
       "                      2.8330e+00, 9.3719e-01, 7.0478e-03, 3.2794e+00, 9.3138e-01, 1.0023e-01,\n",
       "                      2.0290e+00, 9.8385e-01, 9.7208e-01, 4.8751e-01, 4.2532e+00, 3.3519e+00,\n",
       "                      2.7905e+00, 1.2503e-01, 2.0453e+00, 1.6759e-19, 3.9786e+00, 5.5600e-01,\n",
       "                      4.7979e+00, 4.6024e-02, 2.3348e+00, 3.1022e-01, 3.6455e+00, 1.6689e+00,\n",
       "                      3.0122e+00, 4.0586e+00, 7.6281e-01, 1.7873e+00, 7.3350e-01, 2.7057e+00,\n",
       "                      1.7710e+00, 5.3012e+00, 7.2880e-01, 0.0000e+00, 3.5634e+00, 3.6537e+00,\n",
       "                      3.6141e+00, 8.0770e-28, 3.9902e+00, 2.8907e+00, 2.5271e+00, 4.2951e+00,\n",
       "                      9.8729e-01, 1.0222e+00, 1.2454e-01, 1.7699e+00, 3.6695e+00, 3.7575e+00,\n",
       "                      1.8456e-03, 9.0176e-02, 3.7225e+00, 3.1668e-04, 3.7371e+00, 1.3985e+00,\n",
       "                      3.9809e+00, 2.0057e+00, 4.0697e+00, 0.0000e+00, 7.0351e-01, 1.3648e-01,\n",
       "                      1.1977e+00, 1.2363e+00, 6.0916e+00, 9.8201e-01, 3.6749e+00, 1.0545e+00,\n",
       "                      3.0998e+00, 3.7248e+00, 5.9829e-01, 2.8751e+00, 4.6597e+00, 4.3126e+00,\n",
       "                      1.1425e+00, 4.2017e-01], device='mps:0')),\n",
       "             ('user_tower.6.running_var',\n",
       "              tensor([1.0142e+01, 3.1910e+01, 1.3971e+02, 3.4085e+01, 6.8977e+01, 8.7611e+00,\n",
       "                      9.5678e+01, 2.5012e+00, 2.0200e+02, 2.2577e+01, 4.3539e-01, 7.4915e+01,\n",
       "                      9.2112e+01, 2.1180e+00, 1.4040e+01, 5.2497e+01, 0.0000e+00, 2.0127e+01,\n",
       "                      9.6204e-01, 1.3085e+02, 6.7902e+01, 4.9273e+00, 8.6654e+01, 3.4903e+00,\n",
       "                      1.7103e+02, 2.0225e+01, 1.0787e+02, 3.8056e+00, 1.2970e+02, 9.8446e+01,\n",
       "                      3.7557e+01, 2.1542e+00, 5.5691e-01, 3.3991e-01, 9.7583e+01, 1.2513e+01,\n",
       "                      1.8309e+02, 0.0000e+00, 1.0845e+02, 7.1735e+01, 1.5270e+01, 1.3151e-02,\n",
       "                      4.6171e-01, 4.1052e+00, 1.1368e+01, 7.6773e-14, 9.0424e+00, 1.1476e+02,\n",
       "                      2.1602e+01, 6.1968e+00, 6.9812e+01, 4.3536e+01, 1.6868e+00, 9.9579e-19,\n",
       "                      5.4616e+00, 1.4200e+01, 3.1900e-03, 6.6411e+00, 1.8922e+00, 4.9272e-01,\n",
       "                      3.9842e+00, 1.3410e+01, 1.5753e+01, 5.1550e-01, 1.3753e+02, 8.9464e+01,\n",
       "                      7.8600e+01, 7.4266e-01, 5.5580e+01, 1.2529e-20, 1.1403e+02, 7.3266e+00,\n",
       "                      1.7729e+02, 3.8894e-02, 4.7029e+01, 2.5773e+00, 9.4343e+01, 4.5835e+01,\n",
       "                      6.9963e+00, 1.5674e+02, 1.0934e+01, 3.6409e+01, 1.8687e+00, 8.4378e+01,\n",
       "                      3.9037e+01, 2.0497e+02, 1.6702e+00, 0.0000e+00, 6.9846e+00, 8.5103e+01,\n",
       "                      9.5185e+01, 1.9792e-28, 8.8830e+01, 8.4700e+01, 8.4641e+01, 1.1804e+02,\n",
       "                      2.0937e+01, 2.8273e+00, 1.3167e-01, 4.1042e+01, 1.1041e+02, 9.7194e+01,\n",
       "                      6.9073e-04, 4.5382e-01, 5.6622e+00, 2.6715e-05, 8.1498e+00, 1.8328e+00,\n",
       "                      1.2673e+02, 5.5070e+01, 1.5041e+02, 0.0000e+00, 1.0158e+01, 1.9563e-01,\n",
       "                      3.9876e+00, 2.8479e+01, 1.1304e+01, 2.0704e+00, 7.4428e+00, 1.9576e+01,\n",
       "                      8.7806e+01, 1.1234e+02, 8.2414e+00, 9.4818e+01, 1.5003e+02, 1.3539e+02,\n",
       "                      2.4331e+01, 3.9800e+00], device='mps:0')),\n",
       "             ('user_tower.6.num_batches_tracked',\n",
       "              tensor(45010, device='mps:0')),\n",
       "             ('user_tower.8.weight',\n",
       "              tensor([[ 0.0815,  0.0949,  0.0608,  ...,  0.0293,  0.2211,  0.1689],\n",
       "                      [-0.2955, -0.2004, -0.2758,  ..., -0.1592, -0.2489, -0.1463],\n",
       "                      [-0.2660, -0.3169, -0.3019,  ..., -0.0256, -0.3269,  0.0297],\n",
       "                      ...,\n",
       "                      [-0.0225, -0.3351, -0.1814,  ..., -0.1688, -0.2356, -0.0006],\n",
       "                      [ 0.0897, -0.2303, -0.0770,  ..., -0.1033, -0.0909,  0.0719],\n",
       "                      [-0.1718, -0.2722, -0.1183,  ..., -0.1768, -0.2584, -0.1465]],\n",
       "                     device='mps:0')),\n",
       "             ('user_tower.8.bias',\n",
       "              tensor([ 0.0026,  0.0041, -0.0789, -0.0661, -0.0821, -0.0467,  0.0295,  0.0561,\n",
       "                       0.0137,  0.0223, -0.0580, -0.0760, -0.0598, -0.0439,  0.0731,  0.0741,\n",
       "                       0.0453,  0.0697, -0.0929,  0.0129, -0.0215, -0.0971,  0.0650, -0.0291,\n",
       "                      -0.0022,  0.0269,  0.0113, -0.0643,  0.0810, -0.0139, -0.0138, -0.0098,\n",
       "                      -0.0082,  0.0908,  0.0600, -0.0813, -0.0404, -0.0285, -0.0347, -0.1008,\n",
       "                      -0.0397, -0.0644,  0.0666, -0.1046,  0.0877, -0.0360,  0.0708,  0.0264,\n",
       "                       0.0368, -0.0928, -0.0196,  0.0492,  0.0962, -0.0282, -0.0254, -0.0132,\n",
       "                      -0.0572, -0.0921,  0.0472, -0.0254, -0.0741, -0.0241, -0.0101,  0.0242],\n",
       "                     device='mps:0')),\n",
       "             ('user_tower.9.weight',\n",
       "              tensor([0.3898, 0.4465, 0.4628, 0.4855, 0.3980, 0.5060, 0.3665, 0.4538, 0.5068,\n",
       "                      0.4032, 0.3621, 0.4582, 0.3900, 0.5844, 0.5582, 0.4553, 0.3765, 0.6443,\n",
       "                      0.5227, 0.4294, 0.5493, 0.5480, 0.4420, 0.4109, 0.7520, 0.4097, 0.6589,\n",
       "                      0.4824, 0.3532, 0.4687, 0.5053, 0.4669, 0.3173, 0.4250, 0.4363, 0.5583,\n",
       "                      0.4523, 0.5003, 0.5219, 0.5856, 0.4661, 0.6302, 0.4149, 0.3659, 0.5973,\n",
       "                      0.5131, 0.6823, 0.3521, 0.4772, 0.5516, 0.3924, 0.4737, 0.4969, 0.4735,\n",
       "                      0.8363, 0.6496, 0.3879, 0.5331, 0.4233, 0.3480, 0.4406, 0.6681, 0.4284,\n",
       "                      0.4693], device='mps:0')),\n",
       "             ('user_tower.9.bias',\n",
       "              tensor([-0.0695,  0.2193,  0.0595,  0.0183,  0.2743,  0.0035,  0.0376,  0.2566,\n",
       "                       0.1506,  0.1590, -0.0405, -0.0710,  0.4877,  0.0389,  0.1115,  0.0259,\n",
       "                       0.0340, -0.2332, -0.0716,  0.0949,  0.2624, -0.1335,  0.1821, -0.2524,\n",
       "                      -0.2842,  0.6642, -0.0955, -0.4265,  0.5223, -0.2433, -0.5090, -0.2859,\n",
       "                       0.1383, -0.2406,  0.2056,  0.2750, -0.1427, -0.3226, -0.0076, -0.1630,\n",
       "                      -0.3817, -0.2229,  0.2586,  0.0998, -0.0098,  0.1663,  0.1547,  0.2615,\n",
       "                      -0.1352, -0.0573, -0.1802, -0.0087,  0.1131, -0.0805,  0.0894,  0.2116,\n",
       "                      -0.3700,  0.1903,  0.2943, -0.3735, -0.2876, -0.1047, -0.2093, -0.1170],\n",
       "                     device='mps:0')),\n",
       "             ('user_tower.9.running_mean',\n",
       "              tensor([-0.2830, -2.0630, -2.4509,  1.0878,  2.2903, -1.0078, -0.2493, -0.6849,\n",
       "                      -0.5851,  3.1318, -1.4969,  0.8159, -2.9310,  0.1531,  0.2441, -3.0811,\n",
       "                      -0.8389, -2.9799,  0.6649, -2.5386,  2.3648, -3.1560, -0.3137, -2.9255,\n",
       "                      -1.7041, -0.8036,  0.8207,  0.6694,  0.0401,  2.0183, -1.8281,  1.7682,\n",
       "                      -1.1033,  1.8125, -0.9790,  3.2244,  1.0995,  0.4480, -0.0205,  0.3702,\n",
       "                       1.7055, -0.7205,  2.6157, -0.8454,  0.1324,  1.1668,  2.0858,  1.4591,\n",
       "                      -3.4136,  0.2127, -2.9664, -2.3655,  0.5538,  3.3533, -2.2183,  2.9784,\n",
       "                      -2.2505,  3.2439, -0.8234,  3.3792, -0.0124, -3.1652,  0.1788, -3.1620],\n",
       "                     device='mps:0')),\n",
       "             ('user_tower.9.running_var',\n",
       "              tensor([ 87.6710, 242.9074, 268.2435, 144.1562, 290.6518, 145.4205, 128.6888,\n",
       "                       46.3985, 118.3287, 368.9725, 228.0907, 134.6009, 145.9823,  65.3515,\n",
       "                       96.2962, 286.1656, 188.5911, 159.0696, 146.0258, 237.6696, 142.8704,\n",
       "                      199.3353,  44.8299, 293.1779,  83.9172,  78.7055,  66.0878,  60.1772,\n",
       "                       88.7522, 235.1760,  86.7484, 199.0751, 167.5857, 162.9058,  66.7088,\n",
       "                      255.0657, 188.2584,  36.3256,  52.2304,  84.0057, 161.6426,  16.7384,\n",
       "                      297.4030, 136.5779,  51.5437, 140.1082,  97.6691, 203.5118, 320.3826,\n",
       "                       77.3281, 384.8635, 308.1373, 132.9435, 340.2286,  27.7882, 169.7312,\n",
       "                      223.9003, 221.4899, 137.9619, 164.8282,  74.8260, 182.7320,  59.6401,\n",
       "                      386.8826], device='mps:0')),\n",
       "             ('user_tower.9.num_batches_tracked',\n",
       "              tensor(45010, device='mps:0')),\n",
       "             ('event_tower.0.weight',\n",
       "              tensor([[-8.1546e-01,  6.6873e-01,  9.6393e-02],\n",
       "                      [-8.1390e-01, -5.5061e-01,  2.5340e-02],\n",
       "                      [ 2.4218e-01, -4.7739e-01, -1.0334e-01],\n",
       "                      [-1.0231e+00, -4.8337e-02,  2.4741e-02],\n",
       "                      [-1.5990e-02,  1.1082e+00,  8.2635e-02],\n",
       "                      [-9.3772e-01,  8.3163e-01, -1.0471e-02],\n",
       "                      [-1.3265e+00,  2.8077e-01,  3.5785e-02],\n",
       "                      [-1.2775e+00,  2.7532e-01, -2.3483e-02],\n",
       "                      [ 6.5223e-01, -2.1425e-01, -6.5973e-02],\n",
       "                      [-1.0835e-03, -1.4501e+00, -6.6976e-02],\n",
       "                      [ 3.7833e-01, -2.7085e-01,  2.2042e-01],\n",
       "                      [ 1.6854e-01,  2.3252e+00,  3.2076e-01],\n",
       "                      [ 2.5764e-01,  2.6938e-01, -3.7481e-01],\n",
       "                      [-4.4104e-01,  3.2951e-01, -2.6366e-01],\n",
       "                      [ 3.3365e-01,  4.6184e-01, -4.2136e-01],\n",
       "                      [ 5.9721e-02, -5.3508e-01,  6.2510e-02],\n",
       "                      [ 5.7608e-01,  5.0240e-01, -4.2430e-01],\n",
       "                      [-1.1153e+00,  1.4509e-01, -9.0793e-02],\n",
       "                      [ 1.6563e-01,  1.6540e-01, -8.2556e-02],\n",
       "                      [ 3.3560e-01,  2.3920e-01,  8.0551e-02],\n",
       "                      [ 3.9762e-01,  4.3975e-01,  4.4176e-01],\n",
       "                      [ 1.3621e-01,  9.7430e-01,  5.6870e-01],\n",
       "                      [-7.2580e-01,  1.1833e+00,  1.6661e-01],\n",
       "                      [ 4.4242e-02, -7.9446e-02, -4.0409e-01],\n",
       "                      [-7.2609e-01, -2.7994e-01, -2.8331e-01],\n",
       "                      [-6.0706e-01,  4.0341e-01, -3.2781e-02],\n",
       "                      [ 2.6362e-02,  6.3948e-01, -2.5937e-03],\n",
       "                      [-1.2451e+00, -4.7736e-01,  1.5321e-02],\n",
       "                      [ 6.1887e-01, -6.4375e-01,  5.7740e-02],\n",
       "                      [-8.1005e-01,  6.7487e-01,  1.4013e-02],\n",
       "                      [-1.0865e+00, -7.3597e-02,  3.4756e-02],\n",
       "                      [ 2.6453e-01, -1.6478e-01,  6.1047e-01],\n",
       "                      [-1.0393e+00,  5.0240e-01,  6.2550e-03],\n",
       "                      [ 3.3209e-01,  8.5147e-02, -4.7190e-01],\n",
       "                      [-1.0142e+00,  1.1524e-01, -2.6261e-02],\n",
       "                      [-4.8299e-01,  1.0454e+00, -2.2056e-01],\n",
       "                      [ 6.2474e-01, -1.5398e-01, -2.2434e-02],\n",
       "                      [-5.7183e-01, -1.0491e+00, -3.6940e-02],\n",
       "                      [ 4.9907e-01, -3.7330e-01,  9.7800e-03],\n",
       "                      [-9.5520e-02, -6.5864e-01, -5.1714e-01],\n",
       "                      [-4.8025e-01,  1.0343e+00,  1.4239e-02],\n",
       "                      [-4.2387e-01,  1.0524e+00, -1.6892e-03],\n",
       "                      [ 8.6482e-02, -1.2363e+00,  2.5689e-02],\n",
       "                      [ 5.0175e-01,  4.2797e-01,  2.4166e-01],\n",
       "                      [ 4.7951e-03, -2.0505e+00, -4.0338e-02],\n",
       "                      [ 3.8256e-02,  1.3414e+00, -2.3174e-02],\n",
       "                      [ 4.4502e-01, -9.7452e-02, -5.2007e-01],\n",
       "                      [ 9.5343e-03, -1.5433e+00, -8.4744e-03],\n",
       "                      [-2.3370e-01,  1.1648e+00,  4.7062e-02],\n",
       "                      [ 3.7450e-01, -4.0975e-01, -2.7675e-01],\n",
       "                      [ 5.0683e-01, -4.3163e-02,  1.2908e-01],\n",
       "                      [-7.3124e-01, -5.9993e-01,  1.2245e-01],\n",
       "                      [ 4.1559e-01, -3.2131e-01,  7.0226e-02],\n",
       "                      [ 3.0010e-01, -6.1195e-01,  6.7120e-01],\n",
       "                      [-7.3849e-02, -1.7988e+00,  3.0961e-02],\n",
       "                      [ 1.4153e-01, -2.4530e-01, -4.9861e-01],\n",
       "                      [ 5.6298e-01, -4.1463e-01,  5.1127e-02],\n",
       "                      [ 3.4327e-02,  1.5913e+00, -2.8463e-02],\n",
       "                      [-1.0548e-01, -4.0950e-01, -5.3450e-01],\n",
       "                      [ 4.4974e-01, -6.0174e-01, -1.8236e-01],\n",
       "                      [-1.3766e+00,  3.1226e-01,  1.4824e-02],\n",
       "                      [ 2.3501e-01, -1.8249e-01,  5.2579e-01],\n",
       "                      [ 1.7331e-01,  1.6305e-01,  6.2313e-01],\n",
       "                      [-5.3434e-01, -1.3726e+00,  4.0321e-02],\n",
       "                      [ 3.9289e-01, -2.5456e-01,  5.4201e-01],\n",
       "                      [-4.5839e-01,  1.0160e+00,  1.2795e-02],\n",
       "                      [ 4.4060e-01,  4.0379e-01, -1.5621e-01],\n",
       "                      [-1.0298e-01, -9.6836e-01, -3.0904e-02],\n",
       "                      [ 4.5569e-01, -1.9235e-01, -2.1163e-01],\n",
       "                      [ 4.4709e-01, -3.4049e-01, -2.7241e-01],\n",
       "                      [ 2.2689e-01, -1.6143e-01,  3.0042e-01],\n",
       "                      [-2.5590e-01, -4.5504e-01,  3.7162e-01],\n",
       "                      [ 3.4936e-01,  3.0827e-01,  6.1330e-01],\n",
       "                      [-6.2336e-01,  8.3272e-01, -2.7701e-02],\n",
       "                      [ 3.0732e-01,  1.3698e-01, -4.7316e-01],\n",
       "                      [ 2.5490e-01, -3.6412e-01,  3.5167e-01],\n",
       "                      [-1.1112e+00, -4.9497e-01,  1.0802e-02],\n",
       "                      [-9.9459e-01, -3.1698e-01,  4.6187e-02],\n",
       "                      [-1.2365e-01, -1.2592e+00,  1.8958e-02],\n",
       "                      [ 1.7471e-02, -3.8315e-01, -4.5481e-01],\n",
       "                      [ 3.4373e-01,  3.6511e-01, -3.5038e-02],\n",
       "                      [-3.5190e-01, -1.1369e+00,  2.8792e-01],\n",
       "                      [ 3.0109e-01, -1.8558e-01, -7.8030e-02],\n",
       "                      [ 9.5691e-02, -9.2414e-01,  2.6808e-02],\n",
       "                      [ 4.9340e-01,  3.3180e-02, -6.6058e-02],\n",
       "                      [ 3.4113e-03, -9.3688e-01, -8.0421e-02],\n",
       "                      [-8.4039e-01,  3.0275e-02, -4.4293e-03],\n",
       "                      [ 1.3862e-03, -1.0570e+00, -5.3822e-02],\n",
       "                      [ 2.6405e-02,  2.0122e-01, -4.5355e-01],\n",
       "                      [ 3.1447e-01,  2.3627e-01,  3.6071e-02],\n",
       "                      [-5.1422e-01, -9.8763e-01, -7.4523e-02],\n",
       "                      [-3.8383e-01,  7.4737e-01,  1.0887e-03],\n",
       "                      [-6.0681e-02,  1.7620e+00,  7.6962e-02],\n",
       "                      [ 3.3597e-01,  3.0913e-01,  1.9312e-02],\n",
       "                      [ 4.9955e-01, -2.5284e-01, -3.1872e-01],\n",
       "                      [-1.2056e+00,  3.5032e-01,  1.1471e-02],\n",
       "                      [-2.9493e-02,  1.4791e+00, -4.0210e-02],\n",
       "                      [-2.6067e-01,  1.1526e+00, -6.2944e-02],\n",
       "                      [ 2.7268e-01, -6.5331e-01, -1.0050e-01],\n",
       "                      [-7.4032e-01,  4.8589e-01,  1.8519e-01],\n",
       "                      [-9.9500e-01, -4.6847e-01, -3.5647e-02],\n",
       "                      [ 1.5047e-01, -2.1564e-01, -6.7783e-01],\n",
       "                      [ 5.4419e-01,  1.1952e-01, -3.1745e-01],\n",
       "                      [-4.1046e-01, -5.5280e-02,  2.6171e-01],\n",
       "                      [-8.6473e-01, -6.7242e-01, -1.4055e-03],\n",
       "                      [-4.9295e-01,  1.1656e+00,  2.9853e-02],\n",
       "                      [ 2.7823e-01, -6.5395e-03, -1.7073e-01],\n",
       "                      [-2.1311e-01, -1.1019e+00, -6.1181e-01],\n",
       "                      [-1.1902e+00,  2.6650e-01,  4.2219e-02],\n",
       "                      [ 1.2645e-01, -4.0153e-01,  1.8004e-01],\n",
       "                      [ 1.5080e-01,  1.4799e+00,  4.2956e-01],\n",
       "                      [-6.1953e-01,  7.1428e-01,  7.5281e-02],\n",
       "                      [-1.2218e-01,  1.6973e-01, -6.4265e-01],\n",
       "                      [-1.2525e-01, -1.3672e+00,  5.1080e-03],\n",
       "                      [ 2.3809e-01,  1.3664e-01,  4.1746e-01],\n",
       "                      [-4.1240e-01, -1.4888e+00,  1.3703e-01],\n",
       "                      [ 1.1986e-01,  3.0423e-01,  4.1683e-02],\n",
       "                      [ 1.1085e-01,  1.1753e+00, -2.3877e-02],\n",
       "                      [ 5.9755e-01, -1.7055e-01, -1.8982e-01],\n",
       "                      [-3.8379e-01,  4.7007e-01,  3.3275e-01],\n",
       "                      [-3.7813e-01,  5.7527e-02,  2.5993e-01],\n",
       "                      [-1.1465e-01, -3.3204e-02, -5.7086e-01],\n",
       "                      [ 3.6316e-01,  4.9906e-02,  3.0070e-01],\n",
       "                      [ 5.9499e-01,  2.0999e-01,  1.0924e-01],\n",
       "                      [ 2.0732e-01, -1.5251e-01, -5.2741e-01],\n",
       "                      [ 1.0743e-02, -1.7246e+00, -2.8859e-02],\n",
       "                      [-7.6689e-01,  3.2197e-01, -4.2012e-02],\n",
       "                      [ 1.6965e-01,  2.3557e-01,  1.5939e-01],\n",
       "                      [ 2.9470e-01,  6.1544e-01,  2.5927e-01],\n",
       "                      [ 2.4513e-01, -3.6770e-01,  2.9762e-01],\n",
       "                      [-2.2187e-01,  1.8058e+00, -5.7960e-01],\n",
       "                      [-3.3100e-01,  1.1446e+00,  4.6694e-02],\n",
       "                      [-5.8320e-01,  4.1404e-01, -2.6386e-02],\n",
       "                      [ 1.7997e-01,  2.7191e-01, -2.4254e-01],\n",
       "                      [ 8.5235e-02, -7.7287e-01,  1.2672e-01],\n",
       "                      [-3.7046e-01, -5.1196e-01,  1.5805e-01],\n",
       "                      [ 2.6900e-01,  2.6729e-01, -1.7471e-01],\n",
       "                      [-3.1557e-01,  2.9040e-01,  2.3365e-01],\n",
       "                      [ 1.2862e-01,  5.2365e-01,  5.5912e-01],\n",
       "                      [ 1.5683e-01, -1.6616e-01,  3.7981e-01],\n",
       "                      [ 9.9483e-02,  2.4841e-01,  8.3964e-02],\n",
       "                      [ 2.1122e-01, -5.7757e-01, -9.0447e-02],\n",
       "                      [-3.1867e-01,  1.8892e+00,  8.9119e-02],\n",
       "                      [ 5.0216e-01, -1.9048e-01, -1.5260e-01],\n",
       "                      [-1.0862e+00, -8.1470e-02, -6.0990e-02],\n",
       "                      [ 5.3104e-01, -4.2576e-01, -4.1757e-01],\n",
       "                      [ 8.2657e-02,  9.0625e-01, -4.7688e-02],\n",
       "                      [ 3.2858e-01,  2.4725e-01,  4.4002e-01],\n",
       "                      [-1.4611e-01,  1.1368e+00, -2.7352e-02],\n",
       "                      [ 2.1507e-01,  8.4456e-01,  2.0565e-01],\n",
       "                      [ 2.9660e-01,  1.5655e-01,  1.3637e-01],\n",
       "                      [ 3.8152e-01,  2.5669e-01,  2.4747e-02],\n",
       "                      [-5.0814e-01, -3.8214e-02, -2.7048e-01],\n",
       "                      [ 4.3495e-01, -7.2009e-01,  2.8737e-02],\n",
       "                      [-7.2025e-01, -1.6511e-01,  3.7582e-01],\n",
       "                      [ 3.4126e-01, -5.1891e-01, -7.5447e-02],\n",
       "                      [ 2.6365e-01, -5.9794e-02, -7.5111e-01],\n",
       "                      [-5.2575e-01,  7.2460e-01, -3.1366e-02],\n",
       "                      [ 7.5966e-02, -1.3498e+00,  2.4524e-02],\n",
       "                      [-6.2019e-01,  5.2924e-01,  2.0848e-01],\n",
       "                      [ 5.3766e-01,  1.0523e-02, -3.2081e-01],\n",
       "                      [ 6.4789e-01, -1.0294e-01,  3.2346e-02],\n",
       "                      [-5.8902e-01,  7.9301e-01, -6.0891e-02],\n",
       "                      [-1.9874e-01,  1.7896e+00, -5.1951e-01],\n",
       "                      [-1.2174e+00, -2.8456e-01,  6.4620e-02],\n",
       "                      [ 2.9636e-02, -5.0084e-01, -3.5497e-01],\n",
       "                      [ 7.9137e-01, -5.8709e-01, -2.9745e-01],\n",
       "                      [ 1.2664e-01, -4.1293e-01,  1.8190e-01],\n",
       "                      [ 6.1330e-01,  5.2499e-01, -3.5684e-01],\n",
       "                      [ 3.9543e-01, -3.3875e-01,  5.1829e-01],\n",
       "                      [ 4.3086e-01, -5.5897e-01, -2.5457e-01],\n",
       "                      [ 2.2306e-03, -5.2452e-01, -8.7735e-02],\n",
       "                      [ 3.5216e-01,  5.3086e-01,  3.3101e-01],\n",
       "                      [ 6.5582e-01,  3.4363e-01, -2.5120e-02],\n",
       "                      [ 5.6093e-01,  5.2159e-01, -8.2303e-02],\n",
       "                      [-1.5192e+00,  6.5190e-02,  2.9291e-02],\n",
       "                      [-3.8627e-01,  4.3353e-01,  3.6940e-01],\n",
       "                      [-7.8149e-01, -4.1435e-01, -1.7538e-01],\n",
       "                      [-8.3229e-01, -7.0652e-01, -6.3130e-02],\n",
       "                      [ 1.8024e-01,  4.5692e-01, -3.6996e-01],\n",
       "                      [ 7.4145e-02,  1.6519e+00, -2.2750e-02],\n",
       "                      [ 1.7281e-01,  2.5808e-01, -5.5603e-02],\n",
       "                      [ 9.7414e-02,  1.0505e-01,  3.3989e-01],\n",
       "                      [-7.3202e-01,  3.2115e-01,  2.3896e-01],\n",
       "                      [-1.1950e-01,  1.8235e+00, -2.6446e-01],\n",
       "                      [-8.6988e-01,  8.1278e-01, -1.2205e-01],\n",
       "                      [ 2.5645e-01,  5.2753e-01,  3.2702e-01],\n",
       "                      [ 8.7856e-02,  2.8018e-01, -3.7070e-01],\n",
       "                      [ 2.9846e-01,  2.7371e-01,  1.5757e-02],\n",
       "                      [ 3.8724e-01, -6.5783e-01,  4.8843e-01],\n",
       "                      [ 1.9664e-02, -1.2176e+00, -9.0617e-02],\n",
       "                      [ 3.0939e-03, -4.8483e-01, -3.4918e-01],\n",
       "                      [ 5.3979e-02,  1.1557e+00, -2.8111e-02],\n",
       "                      [-7.1424e-01, -1.1129e+00,  1.2123e-01],\n",
       "                      [ 1.7847e-01,  3.5363e-01,  2.3394e-01],\n",
       "                      [ 5.0862e-01,  6.0942e-02,  6.0755e-02],\n",
       "                      [ 5.0748e-01, -1.8295e-01, -1.7255e-01],\n",
       "                      [ 1.9296e-02, -8.7233e-01, -9.8231e-02],\n",
       "                      [ 1.1180e-01, -1.9636e-01,  6.7245e-01],\n",
       "                      [ 5.4645e-01, -2.9120e-01, -3.6032e-02],\n",
       "                      [-9.2984e-01, -6.1945e-01, -5.5046e-02],\n",
       "                      [ 4.8837e-01,  4.9982e-02, -6.1852e-02],\n",
       "                      [ 1.9079e-03, -2.5884e-01, -1.6253e-01],\n",
       "                      [-1.2492e-01, -1.2877e+00,  3.8500e-03],\n",
       "                      [-7.6085e-01,  7.3002e-01, -3.0393e-01],\n",
       "                      [ 5.0167e-01, -5.2512e-01, -1.5234e-02],\n",
       "                      [ 9.8995e-02,  3.4844e-01, -3.1049e-01],\n",
       "                      [-6.4814e-01,  8.9528e-01,  2.1915e-02],\n",
       "                      [-3.7767e-01, -6.2742e-01,  2.4237e-01],\n",
       "                      [ 3.2700e-01,  6.0511e-01,  4.4722e-01],\n",
       "                      [-1.2759e+00, -3.9225e-01,  1.5901e-02],\n",
       "                      [-8.4999e-01, -1.2334e-01, -1.0860e-01],\n",
       "                      [-1.4717e-01, -2.7017e-01, -5.8381e-01],\n",
       "                      [-2.4604e-01,  1.9632e-01, -6.1061e-01],\n",
       "                      [-9.3945e-01, -6.4452e-01,  3.6346e-02],\n",
       "                      [-7.7531e-01,  5.5352e-01, -1.0092e-01],\n",
       "                      [-9.5665e-02, -1.8703e+00, -7.3008e-03],\n",
       "                      [-3.5354e-01,  1.0765e+00,  3.8083e-02],\n",
       "                      [ 2.4095e-02, -2.1029e-02, -5.6134e-01],\n",
       "                      [-7.8556e-02, -1.8927e+00,  4.7182e-03],\n",
       "                      [ 1.7443e-01,  2.1601e+00,  3.1706e-01],\n",
       "                      [-3.4942e-01, -4.6253e-01, -8.0518e-02],\n",
       "                      [ 2.0141e-01, -2.6642e-01,  5.4674e-02],\n",
       "                      [ 4.1102e-01,  9.2152e-02, -1.3143e-01],\n",
       "                      [-2.9294e-02,  2.3207e-01, -5.5321e-01],\n",
       "                      [-7.7885e-02,  1.2309e+00,  2.4950e-02],\n",
       "                      [ 2.3951e-01,  1.0040e-01,  1.5055e-01],\n",
       "                      [-5.0898e-01,  6.8680e-01,  1.6035e-02],\n",
       "                      [ 3.8491e-01,  3.3084e-01,  3.2524e-01],\n",
       "                      [-6.2329e-01,  7.6447e-01,  4.7763e-02],\n",
       "                      [-1.8449e-01, -1.1557e+00,  2.9096e-02],\n",
       "                      [ 5.4081e-01, -9.3447e-02, -5.9204e-01],\n",
       "                      [ 2.4877e-01, -4.6731e-01,  4.1018e-01],\n",
       "                      [-1.2809e+00,  2.8002e-01, -3.4563e-02],\n",
       "                      [ 2.1881e-02, -2.6855e-01, -1.2653e-01],\n",
       "                      [ 2.0254e-01, -7.4258e-01,  2.7849e-01],\n",
       "                      [ 3.5365e-01,  4.0115e-01,  3.7987e-01],\n",
       "                      [ 1.7640e-01, -3.9804e-01,  1.1416e-01],\n",
       "                      [ 7.4053e-02,  6.2399e-01,  5.1573e-01],\n",
       "                      [ 3.3532e-01, -3.7725e-01,  9.9690e-02],\n",
       "                      [ 8.4133e-02,  1.0084e+00,  4.2473e-02],\n",
       "                      [ 1.5182e-01,  1.8370e+00,  3.8111e-01],\n",
       "                      [ 4.1139e-01, -5.5788e-01,  4.7392e-01],\n",
       "                      [ 3.5136e-01,  4.1589e-01, -1.3237e-01],\n",
       "                      [ 4.6628e-01, -5.6434e-01, -1.9285e-02],\n",
       "                      [ 6.8743e-02, -3.0476e-02, -4.6260e-01],\n",
       "                      [ 3.8562e-01, -1.3525e-02,  4.8526e-01],\n",
       "                      [ 1.0871e-01,  1.2469e-01,  5.1297e-01],\n",
       "                      [-1.6126e-01, -1.5177e+00,  1.2084e-02],\n",
       "                      [ 1.7560e-01, -1.7962e-01,  1.4055e-01],\n",
       "                      [ 4.2718e-02,  1.4981e-01, -2.8999e-01],\n",
       "                      [-8.8226e-01, -1.9345e-01,  6.6010e-03],\n",
       "                      [-2.9214e-01,  4.9500e-01,  3.1841e-01],\n",
       "                      [ 6.8115e-01, -3.1970e-02, -1.7203e-01],\n",
       "                      [ 3.5948e-01, -3.2629e-01, -4.1781e-01],\n",
       "                      [ 3.5945e-03, -1.6252e+00, -1.7738e-02]], device='mps:0')),\n",
       "             ('event_tower.0.bias',\n",
       "              tensor([-5.4702e-01, -1.0932e+00,  1.0009e-01, -1.3416e+00,  5.6769e-02,\n",
       "                      -6.2732e-01, -1.0671e+00, -1.4014e+00,  4.4259e-02,  4.3644e-01,\n",
       "                      -7.7883e-02, -2.1331e-01, -4.0754e-01,  2.2557e-02,  4.7660e-02,\n",
       "                      -3.4072e-02,  4.4640e-01, -1.3315e+00, -4.9568e-01,  3.4799e-01,\n",
       "                      -1.5685e-01,  1.3078e-01, -8.3102e-01,  4.4050e-01,  1.0015e-01,\n",
       "                      -1.1507e+00,  3.0585e-01, -9.4598e-01, -1.6017e-01, -9.6345e-01,\n",
       "                      -1.4619e+00,  2.5131e-01, -1.9825e+00,  4.1223e-01, -1.3716e+00,\n",
       "                       1.9191e-01,  2.8222e-01,  8.6162e-02,  3.3381e-01,  4.6497e-01,\n",
       "                      -5.4484e-01, -4.8168e-01,  4.5260e-01,  2.1944e-01, -7.8800e-02,\n",
       "                       2.1002e-01, -1.3102e-01,  2.6794e-01, -9.0374e-01,  2.8640e-01,\n",
       "                      -2.1531e-01,  3.8118e-02, -3.7103e-01, -2.7053e-01, -3.5538e-01,\n",
       "                      -1.2770e-01,  3.6411e-01, -1.0654e-02, -5.2056e-01, -8.1502e-02,\n",
       "                      -1.2849e+00,  2.7967e-01,  1.4278e-01, -5.8766e-01, -9.4653e-02,\n",
       "                      -1.0179e+00,  1.8016e-01,  1.4076e-01, -4.8644e-01,  3.1634e-01,\n",
       "                      -3.8137e-01,  7.7566e-02,  5.2610e-02, -1.0815e+00, -4.2429e-01,\n",
       "                      -6.0907e-01, -8.2708e-01, -1.0015e+00,  2.1733e-01,  3.2209e-01,\n",
       "                       5.7557e-03,  5.2865e-01, -3.9789e-02,  3.3213e-01, -2.8956e-01,\n",
       "                      -4.0010e-01, -8.9568e-01, -7.9855e-01, -3.4769e-01, -2.5177e-01,\n",
       "                       3.3150e-02, -5.7865e-01,  1.1372e-01, -1.0281e-01,  3.9141e-01,\n",
       "                      -1.6902e+00, -3.8759e-01, -6.4449e-01, -3.6316e-02, -3.0607e-01,\n",
       "                      -1.3892e+00, -4.8883e-01,  4.3270e-01, -2.0071e-01, -9.1783e-01,\n",
       "                      -1.8109e-01,  2.0215e-01,  4.8158e-01, -1.8740e+00, -5.8944e-01,\n",
       "                      -5.0467e-01, -1.9584e+00,  1.4364e-01, -1.6739e-01, -8.0581e-02,\n",
       "                      -5.0327e-01, -2.1182e-01, -5.0967e-01, -5.9820e-03,  3.7011e-01,\n",
       "                      -3.8099e-01, -5.3692e-02, -1.9528e-01, -1.5156e-01, -1.5967e-01,\n",
       "                       2.9824e-01, -4.2951e-01, -6.3845e-02,  5.6545e-01, -3.1169e-01,\n",
       "                      -5.2814e-01, -1.3452e-01, -1.0017e+00,  5.6215e-01, -1.4663e-01,\n",
       "                       7.0185e-04, -2.5965e-01, -1.2396e-02,  4.1876e-01,  5.5501e-01,\n",
       "                       4.4873e-01,  4.7675e-01, -4.1040e-01,  2.9840e-01, -3.6265e-01,\n",
       "                      -5.3317e-01, -3.6751e-01, -1.9918e-01, -4.1674e-01, -4.2605e-01,\n",
       "                      -4.5476e-01, -1.8710e-01,  8.4429e-02,  8.1817e-02, -2.4125e-01,\n",
       "                       4.8600e-02, -9.7885e-02, -1.3391e+00, -1.7248e-01, -3.2403e-01,\n",
       "                      -4.2162e-01, -1.3760e-01, -7.5553e-01,  4.4318e-01, -1.6987e+00,\n",
       "                       4.3379e-01, -3.7890e-03, -2.4391e-01,  6.0296e-01,  3.9564e-01,\n",
       "                      -4.8328e-01,  4.0356e-01, -3.1163e-01,  5.5934e-01,  5.5721e-01,\n",
       "                      -8.5724e-01,  6.8406e-01, -7.6848e-01, -1.7376e+00,  1.6969e-01,\n",
       "                      -2.2303e-02,  4.4132e-01, -1.4118e-01,  3.7176e-01,  1.7643e-01,\n",
       "                      -8.2767e-01,  2.2779e-01, -2.3182e-01, -4.4790e-01, -9.2843e-02,\n",
       "                       3.2521e-02,  1.4349e-02, -3.3885e-01, -3.6930e-01, -4.5821e-01,\n",
       "                      -1.5823e-01,  9.6673e-03, -2.0213e-01,  5.4710e-01, -3.9281e-01,\n",
       "                      -8.6203e-01, -5.6591e-02,  2.2942e-01, -1.8439e-01, -3.2975e-01,\n",
       "                       2.2430e-01, -4.5321e-01, -1.8715e+00,  1.3034e-01, -2.2292e-01,\n",
       "                      -1.1839e+00, -3.9776e-01, -6.6419e-01, -5.4221e-01, -1.4648e+00,\n",
       "                      -1.0777e+00, -1.0437e+00, -3.6683e-01,  3.0504e-01,  1.0377e-01,\n",
       "                       5.2818e-01, -6.6821e-02,  3.4827e-01,  4.5501e-02, -5.2294e-01,\n",
       "                       5.4476e-01, -5.6018e-01, -1.1381e+00,  2.0839e-01, -5.9904e-01,\n",
       "                      -1.1911e+00,  4.4314e-01, -7.3653e-02, -1.5368e+00, -2.7339e-01,\n",
       "                      -2.1154e-02, -6.1025e-01, -3.1170e-01,  1.4161e-01,  1.8330e-01,\n",
       "                       2.1895e-01, -4.2488e-01,  3.1254e-01,  3.3430e-01,  2.4523e-01,\n",
       "                       1.3321e-01,  5.6601e-01,  9.4464e-02,  4.7767e-01,  1.4737e-01,\n",
       "                       3.0260e-01, -4.4176e-01,  3.8417e-01,  3.2372e-01,  1.8940e-01,\n",
       "                       2.1925e-01], device='mps:0')),\n",
       "             ('event_tower.2.weight',\n",
       "              tensor([0.6311, 0.9110, 0.9304, 0.9265, 0.8103, 0.7628, 0.8014, 0.9195, 1.2200,\n",
       "                      1.2727, 0.7968, 0.8383, 0.8953, 0.3165, 1.0824, 1.4314, 0.7838, 0.8596,\n",
       "                      0.9745, 1.3258, 1.4629, 0.8253, 0.7719, 0.7715, 0.3514, 0.7813, 1.1527,\n",
       "                      0.7843, 1.0063, 0.9682, 0.7452, 0.9290, 1.0898, 0.8102, 0.9440, 0.6548,\n",
       "                      0.7622, 0.6695, 1.3069, 1.2640, 0.7109, 0.6526, 0.8833, 1.1763, 1.5595,\n",
       "                      1.4989, 0.8945, 1.3379, 1.1353, 0.9286, 0.8375, 0.5159, 1.2240, 1.4314,\n",
       "                      1.4537, 0.9760, 1.1800, 1.5715, 1.2532, 0.7305, 1.0434, 1.1087, 1.0202,\n",
       "                      0.5495, 1.3279, 0.6731, 1.1503, 0.9366, 1.0117, 0.7640, 1.3791, 0.2976,\n",
       "                      1.1215, 0.9490, 0.8706, 1.1747, 0.9552, 0.8016, 0.8094, 0.9887, 0.9988,\n",
       "                      0.5249, 0.9612, 0.8748, 1.3670, 1.2946, 0.2997, 0.9846, 1.0682, 1.1537,\n",
       "                      0.4798, 1.0345, 0.8958, 1.3042, 1.1389, 0.8154, 1.0128, 1.0158, 1.0427,\n",
       "                      0.5727, 0.9096, 1.1812, 1.1349, 0.3202, 0.8333, 0.7350, 0.9168, 0.9031,\n",
       "                      0.9382, 1.1577, 0.5634, 1.0158, 1.4705, 1.0690, 0.8967, 0.4905, 1.0957,\n",
       "                      1.0221, 0.7713, 0.3949, 0.4108, 1.0726, 0.9235, 1.0457, 0.8928, 1.0998,\n",
       "                      0.7836, 1.2626, 0.6451, 1.1496, 0.6445, 0.6011, 0.4857, 1.2015, 0.6777,\n",
       "                      0.1571, 1.1046, 0.2421, 0.8412, 0.5721, 0.9243, 1.1803, 0.3392, 0.7830,\n",
       "                      0.6326, 1.2347, 1.4320, 1.3228, 1.0615, 0.8117, 1.2568, 1.0759, 0.4523,\n",
       "                      0.9139, 0.4342, 1.1494, 0.9591, 1.0051, 1.4232, 0.3862, 1.1973, 0.7649,\n",
       "                      0.5441, 0.7342, 0.8024, 1.0983, 0.8891, 1.1183, 1.1882, 1.1250, 0.9816,\n",
       "                      0.9602, 1.3170, 1.2871, 0.9089, 0.8610, 0.2861, 0.5603, 0.8881, 0.9106,\n",
       "                      1.0588, 0.9391, 0.6258, 0.3065, 0.8676, 0.3908, 1.0996, 0.9641, 1.4798,\n",
       "                      1.3853, 1.2966, 0.9765, 0.9029, 0.6845, 1.4214, 0.8160, 1.2883, 1.2648,\n",
       "                      0.6966, 1.1328, 0.6392, 0.8472, 0.9878, 0.6787, 0.4409, 0.8404, 1.0373,\n",
       "                      0.7973, 0.4382, 0.8386, 0.8621, 0.5863, 1.0185, 0.7265, 0.9595, 0.4664,\n",
       "                      1.2326, 0.6269, 1.1508, 0.6567, 0.7899, 0.4020, 1.4334, 1.3589, 0.6434,\n",
       "                      0.6224, 0.5261, 0.9757, 1.4910, 0.7744, 1.0605, 0.8442, 1.4239, 0.7589,\n",
       "                      1.1424, 0.9996, 1.6128, 1.0501, 0.9004, 1.3381, 0.1657, 0.6443, 1.3787,\n",
       "                      1.1641, 1.4312, 0.8109, 1.6709, 0.6525, 0.6708, 1.3131, 1.1169, 0.5437,\n",
       "                      0.2364, 1.0982, 1.2354, 1.1678], device='mps:0')),\n",
       "             ('event_tower.2.bias',\n",
       "              tensor([-0.3712, -0.6911, -0.4229, -0.5071,  0.0397, -0.2577, -0.5364, -0.3555,\n",
       "                       0.1131, -0.2791, -0.2330,  0.4317,  0.4285,  0.1289,  0.2401,  0.2965,\n",
       "                       0.3729, -0.5262,  0.3216,  0.3795,  0.1663,  0.0490, -0.1060, -0.5535,\n",
       "                      -0.3335,  0.2131,  0.3126, -0.3594, -0.2513, -0.5630, -0.5800,  0.2990,\n",
       "                      -0.6206,  0.0267, -0.5702, -0.3971, -0.3705,  0.0743,  0.2896,  0.3352,\n",
       "                       0.0052, -0.3706, -0.3332,  0.3337, -0.3931,  0.2310, -0.0688, -0.4235,\n",
       "                      -0.2360, -0.5690, -0.0169, -0.1517,  0.3310,  0.3178, -0.7143,  0.1686,\n",
       "                       0.2109,  0.3177,  0.2789, -0.4877, -0.6720,  0.3032,  0.3515, -0.1863,\n",
       "                       0.0239, -0.1275,  0.0879,  0.1632, -0.0178, -0.2865,  0.3148, -0.0981,\n",
       "                       0.2244, -0.4790,  0.2880,  0.4185, -0.6694, -0.7022, -0.1884, -0.3467,\n",
       "                      -0.2451, -0.2451, -0.3328, -0.0330,  0.5063, -0.1440, -0.0869,  0.0683,\n",
       "                       0.1644,  0.4020, -0.4135, -0.5944,  0.1306,  0.3669,  0.3126, -0.4141,\n",
       "                       0.2261, -0.1051,  0.3806, -0.0460, -0.4624, -0.4566,  0.3513, -0.3953,\n",
       "                      -0.4286, -0.1654, -0.0440,  0.0115, -0.6321,  0.4237,  0.0898, -0.3232,\n",
       "                       0.4276, -0.4102,  0.1461, -0.2005,  0.4120, -0.0880, -0.2534, -0.2762,\n",
       "                      -0.5607,  0.0569, -0.0296, -0.1578, -0.3155, -0.4433, -0.2356,  0.1296,\n",
       "                      -0.4719,  0.4399,  0.1014,  0.2532, -0.2104,  0.4069,  0.3013,  0.0245,\n",
       "                       0.2545,  0.0324,  0.3858, -0.2098,  0.0549,  0.2600, -0.3206,  0.1297,\n",
       "                      -0.4188,  0.2151,  0.2750,  0.2936, -0.1352,  0.2137,  0.2766,  0.6491,\n",
       "                       0.3707, -0.1834, -0.0556,  0.2358,  0.5200, -0.2324, -0.3240, -0.0900,\n",
       "                       0.3903, -0.3047,  0.0443, -0.1279, -0.4956,  0.3068, -0.1191,  0.4033,\n",
       "                       0.3577,  0.0913,  0.2500,  0.1240,  0.2872,  0.3693, -0.1762, -0.4196,\n",
       "                      -0.0405,  0.1504, -0.6053,  0.3055,  0.0887, -0.0940,  0.2659, -0.5173,\n",
       "                      -0.0895, -0.3283, -0.0034,  0.6580,  0.3088,  0.2028, -0.4287,  0.2258,\n",
       "                       0.0550, -0.3508,  0.3308, -0.0927,  0.1944, -0.1496,  0.0399,  0.3798,\n",
       "                       0.0268, -0.2434,  0.1276, -0.2733, -0.0054, -0.2527,  0.2378, -0.3132,\n",
       "                      -0.3192,  0.0575, -0.3498, -0.1047,  0.1147,  0.1376, -0.6149, -0.2125,\n",
       "                      -0.5741, -0.3075,  0.3224, -0.2100,  0.5634, -0.0200,  0.2293,  0.2915,\n",
       "                      -0.0846, -0.1166,  0.1795, -0.3668,  0.2536, -0.0911, -0.7128, -0.3204,\n",
       "                       0.2094, -0.2315, -0.0533,  0.1981,  0.3413,  0.1686,  0.2504,  0.5745,\n",
       "                      -0.3678,  0.4319,  0.4223,  0.2683,  0.3214, -0.4152,  0.3315,  0.2966,\n",
       "                      -0.3331,  0.2649,  0.2064, -0.2628, -0.3272,  0.3264,  0.3545, -0.0379],\n",
       "                     device='mps:0')),\n",
       "             ('event_tower.2.running_mean',\n",
       "              tensor([2.1511e+03, 2.0499e+03, 2.8179e-01, 2.5812e+03, 1.4779e+02, 2.3653e+03,\n",
       "                      3.3607e+03, 3.1804e+03, 8.8146e-01, 5.2667e-04, 6.5450e-01, 2.5094e+01,\n",
       "                      1.5552e-01, 8.4751e+02, 2.3778e-01, 1.1662e-01, 5.7812e-01, 2.7069e+03,\n",
       "                      1.8792e-01, 5.1888e-01, 8.0888e-01, 2.6001e+02, 2.0077e+03, 1.3498e-05,\n",
       "                      1.5264e+03, 1.4975e+03, 3.8584e-02, 3.1204e+03, 9.0132e-01, 2.0570e+03,\n",
       "                      2.7538e+03, 5.2065e+01, 2.6187e+03, 2.0604e-01, 2.5143e+03, 1.0093e+03,\n",
       "                      8.6731e-01, 1.3744e+03, 7.0723e-01, 4.8242e+00, 1.2392e+03, 1.0823e+03,\n",
       "                      1.3110e-01, 8.4335e-01, 0.0000e+00, 4.6843e-02, 3.3732e-01, 6.9697e-03,\n",
       "                      6.5713e+02, 3.7217e-01, 7.8567e-01, 1.9406e+03, 6.2310e-01, 4.8515e+01,\n",
       "                      1.7808e+02, 4.3204e-05, 8.2013e-01, 3.9322e-02, 6.1951e+00, 5.2968e-01,\n",
       "                      3.4675e+03, 3.9193e+01, 2.1933e+02, 1.3469e+03, 8.5905e-01, 1.1827e+03,\n",
       "                      5.3577e-01, 2.0704e+02, 5.2333e-01, 4.7718e-01, 4.8825e-01, 1.0048e+03,\n",
       "                      8.1328e+00, 1.5501e+03, 1.7025e-01, 5.5597e-01, 2.7800e+03, 2.5304e+03,\n",
       "                      3.0252e+02, 3.9335e-06, 4.6642e-01, 1.1465e+03, 3.8005e-01, 1.4597e-01,\n",
       "                      6.5849e-01, 0.0000e+00, 2.1007e+03, 0.0000e+00, 1.1339e-03, 4.6406e-01,\n",
       "                      1.1918e+03, 9.7767e+02, 2.6738e+02, 4.8541e-01, 5.2576e-01, 3.0364e+03,\n",
       "                      6.4093e+01, 6.1280e+02, 3.2552e-01, 2.0496e+03, 2.4447e+03, 4.5977e-05,\n",
       "                      5.9096e-01, 1.2896e+03, 2.1493e+03, 1.2884e+03, 2.9716e-01, 3.6362e+01,\n",
       "                      3.0238e+03, 2.7781e-01, 1.1108e+02, 1.6383e+03, 7.4021e+00, 2.8994e+02,\n",
       "                      5.5169e+00, 1.1379e+03, 1.9326e-01, 1.4767e-01, 7.3569e-01, 1.3061e+03,\n",
       "                      1.2092e+03, 7.2184e+00, 6.7909e-01, 8.9996e-01, 6.1355e-03, 0.0000e+00,\n",
       "                      1.8949e+03, 3.2868e-01, 5.6237e-01, 5.1027e-01, 7.6758e+01, 9.0175e+02,\n",
       "                      1.4431e+03, 1.2014e-01, 1.8787e-01, 1.0749e+03, 2.8288e-01, 1.0311e+03,\n",
       "                      2.6078e+02, 4.1262e+01, 1.8816e-01, 2.4509e-01, 9.2856e+02, 6.2204e-01,\n",
       "                      2.6564e+03, 5.1394e-01, 9.3628e-02, 7.1289e-01, 3.6313e+02, 4.2083e-01,\n",
       "                      4.9422e-01, 5.5236e-01, 1.0059e+03, 6.2583e-01, 2.1773e+03, 4.3671e-01,\n",
       "                      3.7323e-03, 1.2992e+03, 1.1484e-01, 1.7725e+03, 5.7900e-01, 9.3040e-01,\n",
       "                      1.4329e+03, 6.9017e+01, 3.1038e+03, 7.9130e-06, 9.4715e-01, 2.7930e-01,\n",
       "                      6.6825e-01, 8.4800e-01, 4.6290e-01, 0.0000e+00, 6.8244e-01, 9.1187e-01,\n",
       "                      7.4712e-01, 3.8296e+03, 1.3485e+03, 1.7789e+03, 2.0048e+03, 5.0230e-02,\n",
       "                      9.8858e-02, 2.1390e-01, 1.1327e+02, 2.0809e+03, 8.1514e+01, 2.0717e+03,\n",
       "                      5.4856e-01, 2.7873e-05, 4.3025e-01, 8.1687e-01, 3.0391e-06, 0.0000e+00,\n",
       "                      6.5186e-02, 1.8861e+03, 3.8519e-01, 7.5066e-01, 6.1834e-01, 3.7614e-06,\n",
       "                      3.9845e+02, 7.4850e-01, 2.2597e+03, 6.5393e-01, 0.0000e+00, 2.8951e+02,\n",
       "                      1.6158e+03, 6.9629e-01, 1.1542e-03, 1.6630e+03, 1.1761e+03, 7.1704e-01,\n",
       "                      3.2038e+03, 2.0206e+03, 1.4825e+01, 7.6378e+01, 2.3743e+03, 1.8513e+03,\n",
       "                      1.9232e+02, 9.4681e+02, 7.3332e-06, 1.6271e+02, 1.6022e+01, 7.8418e+02,\n",
       "                      3.1325e-01, 5.0647e-01, 5.5618e-01, 2.4768e+02, 4.2137e-01, 1.3049e+03,\n",
       "                      7.2477e-01, 1.6237e+03, 4.6635e+02, 4.3258e-01, 1.7079e+00, 3.1777e+03,\n",
       "                      6.0619e-06, 4.3897e-01, 7.1141e-01, 3.1020e-01, 3.4876e+02, 5.2642e-01,\n",
       "                      1.4658e-01, 7.6577e+01, 8.4177e-01, 4.2341e-01, 6.4401e-01, 2.1336e-05,\n",
       "                      8.1664e-01, 2.5471e+02, 3.8415e+02, 3.2491e-01, 1.3608e-05, 2.2112e+03,\n",
       "                      1.0629e+03, 8.6414e-01, 2.7286e-01, 0.0000e+00], device='mps:0')),\n",
       "             ('event_tower.2.running_var',\n",
       "              tensor([1.3623e+04, 1.2591e+04, 1.5979e+02, 1.9795e+04, 9.1133e+02, 1.7029e+04,\n",
       "                      3.3443e+04, 3.1046e+04, 1.5628e+03, 1.7051e-03, 8.6415e+02, 2.4342e+03,\n",
       "                      4.8344e+01, 1.0924e+04, 1.1296e+02, 2.7734e+01, 6.6927e+02, 2.4529e+04,\n",
       "                      7.0795e+01, 5.4170e+02, 1.3160e+03, 2.6684e+04, 1.3100e+04, 1.6002e-03,\n",
       "                      1.8293e+04, 7.1807e+03, 2.9882e+00, 2.9304e+04, 1.6366e+03, 1.2596e+04,\n",
       "                      2.2476e+04, 8.7382e+03, 2.0574e+04, 8.4829e+01, 1.9583e+04, 9.7974e+03,\n",
       "                      1.5133e+03, 6.4718e+03, 1.0070e+03, 6.8966e+02, 4.6500e+03, 3.6706e+03,\n",
       "                      3.5399e+01, 1.4320e+03, 0.0000e+00, 4.5491e+00, 2.2755e+02, 1.1507e-01,\n",
       "                      1.5332e+03, 2.7793e+02, 1.2430e+03, 1.1668e+04, 7.8218e+02, 8.9035e+03,\n",
       "                      8.1945e+02, 1.6394e-02, 1.3546e+03, 3.3856e+00, 9.7858e+02, 5.6417e+02,\n",
       "                      3.5976e+04, 5.6086e+03, 2.6183e+04, 5.8325e+03, 1.4749e+03, 4.2522e+03,\n",
       "                      5.7592e+02, 4.5373e+02, 5.4995e+02, 4.5706e+02, 4.7743e+02, 1.5436e+04,\n",
       "                      2.2499e+03, 7.6513e+03, 5.7954e+01, 6.1874e+02, 2.3327e+04, 1.8936e+04,\n",
       "                      6.1597e+02, 1.3589e-04, 4.3692e+02, 1.1083e+04, 2.9040e+02, 4.3490e+01,\n",
       "                      8.7164e+02, 0.0000e+00, 1.3389e+04, 0.0000e+00, 3.9320e-02, 4.3305e+02,\n",
       "                      5.7012e+03, 2.9310e+03, 1.2402e+03, 4.7363e+02, 5.5460e+02, 2.7605e+04,\n",
       "                      6.2247e+02, 2.0136e+03, 2.1341e+02, 1.3903e+04, 1.8881e+04, 1.8565e-02,\n",
       "                      7.0035e+02, 1.0166e+04, 1.4178e+04, 4.9970e+03, 1.7710e+02, 8.1874e+03,\n",
       "                      2.6973e+04, 1.5479e+02, 1.0885e+04, 7.9452e+03, 1.3875e+03, 6.3538e+02,\n",
       "                      1.0402e+03, 5.5162e+03, 7.5052e+01, 4.3563e+01, 1.0875e+03, 1.4099e+04,\n",
       "                      9.5856e+03, 1.2501e+03, 9.3018e+02, 1.6298e+03, 5.0685e-01, 0.0000e+00,\n",
       "                      1.1497e+04, 2.1772e+02, 6.3688e+02, 5.2440e+02, 1.6651e+04, 2.5919e+03,\n",
       "                      6.5912e+03, 2.8840e+01, 7.1509e+01, 5.1888e+03, 1.6030e+02, 7.4689e+03,\n",
       "                      2.5908e+04, 4.4964e+03, 7.1265e+01, 1.2101e+02, 3.4261e+03, 7.7758e+02,\n",
       "                      2.2749e+04, 5.2969e+02, 1.7520e+01, 1.0144e+03, 7.5928e+02, 3.5619e+02,\n",
       "                      4.9192e+02, 6.1344e+02, 1.2394e+04, 7.8954e+02, 2.4204e+04, 3.8394e+02,\n",
       "                      2.2878e-01, 5.4951e+03, 2.7378e+01, 1.1744e+04, 6.7239e+02, 1.7419e+03,\n",
       "                      7.1710e+03, 1.3561e+04, 2.8392e+04, 5.4993e-04, 1.8029e+03, 1.5640e+02,\n",
       "                      8.9498e+02, 1.4411e+03, 4.3044e+02, 0.0000e+00, 9.3851e+02, 1.6714e+03,\n",
       "                      1.1210e+03, 4.3660e+04, 1.6771e+04, 1.4775e+04, 1.3566e+04, 5.4038e+00,\n",
       "                      1.9636e+01, 9.1757e+01, 7.5136e+03, 1.5942e+04, 6.3024e+03, 1.6152e+04,\n",
       "                      6.0049e+02, 6.8235e-03, 3.7210e+02, 1.3420e+03, 8.1116e-05, 0.0000e+00,\n",
       "                      8.5609e+00, 1.1302e+04, 2.9579e+02, 1.1339e+03, 7.6819e+02, 1.2426e-04,\n",
       "                      4.0834e+04, 1.1273e+03, 1.6708e+04, 8.5960e+02, 0.0000e+00, 5.9340e+02,\n",
       "                      2.0780e+04, 9.7624e+02, 2.4814e-02, 8.2196e+03, 8.7680e+03, 1.0233e+03,\n",
       "                      3.0878e+04, 1.4953e+04, 2.7185e+03, 1.6717e+04, 1.6852e+04, 1.2596e+04,\n",
       "                      8.1577e+02, 2.7682e+03, 4.7229e-04, 7.8545e+02, 1.5835e+03, 3.0012e+03,\n",
       "                      1.9788e+02, 5.1511e+02, 3.0131e+01, 4.7170e+02, 3.5782e+02, 5.0630e+03,\n",
       "                      1.0589e+03, 7.7272e+03, 9.6940e+02, 3.7435e+02, 7.4737e+02, 3.1287e+04,\n",
       "                      3.2274e-04, 3.8747e+02, 1.0195e+03, 1.9448e+02, 2.5197e+04, 5.5876e+02,\n",
       "                      4.2963e+01, 7.8659e+03, 1.4300e+03, 3.5956e+02, 8.3526e+02, 3.9983e-03,\n",
       "                      1.3369e+03, 2.2331e+04, 9.1821e+02, 2.1316e+02, 1.6264e-03, 1.4723e+04,\n",
       "                      1.1979e+04, 1.5004e+03, 1.4898e+02, 0.0000e+00], device='mps:0')),\n",
       "             ('event_tower.2.num_batches_tracked',\n",
       "              tensor(45010, device='mps:0')),\n",
       "             ('event_tower.4.weight',\n",
       "              tensor([[ 0.2138,  0.0826,  0.1921,  ..., -0.3487, -0.2262, -0.1720],\n",
       "                      [ 0.1024,  0.0992,  0.1090,  ..., -0.2465, -0.2005, -0.1166],\n",
       "                      [ 0.1658, -0.0508,  0.0164,  ...,  0.3782,  0.2819, -0.0382],\n",
       "                      ...,\n",
       "                      [ 0.0783,  0.0611,  0.0761,  ..., -0.5362, -0.2563, -0.0037],\n",
       "                      [ 0.0252,  0.0553,  0.2265,  ..., -0.2204, -0.1447,  0.0741],\n",
       "                      [ 0.2600, -0.0253, -0.1800,  ...,  0.0636,  0.1525,  0.0330]],\n",
       "                     device='mps:0')),\n",
       "             ('event_tower.4.bias',\n",
       "              tensor([-0.3059, -0.2515,  0.8767, -0.2900, -0.1475, -0.4166, -0.1633,  0.1016,\n",
       "                      -0.2654, -0.2682,  0.0165, -0.3482,  1.1827, -0.3095,  0.2775,  0.3762,\n",
       "                       0.1998,  0.2715,  0.0368, -0.1149,  0.0998, -0.1523,  0.2006, -0.0615,\n",
       "                       0.3268, -0.1578,  1.2905,  0.1760,  0.3242, -0.0661, -0.0427,  0.0362,\n",
       "                      -0.2244,  0.0815,  0.2405,  0.8449,  0.2489, -0.2790,  0.4574,  0.3400,\n",
       "                      -0.0215, -0.2479,  0.1259,  1.1043, -0.3354, -0.0816, -0.3472, -0.0920,\n",
       "                      -0.0809, -0.2555,  0.1732,  0.2535, -0.2019,  0.0536, -0.2035, -0.1905,\n",
       "                       0.1035, -0.1618, -0.1698, -0.0174, -0.0762, -0.2377,  0.2228, -0.1657,\n",
       "                      -0.0149, -0.1178,  0.3008, -0.2262,  0.1123, -0.1314,  0.6050,  0.5875,\n",
       "                       0.3600, -0.0024, -0.0267, -0.2615,  0.9044, -0.2458, -0.0747, -0.3830,\n",
       "                      -0.3212, -0.2666, -0.1664,  1.0513,  0.2674, -0.0553, -0.2053,  0.0508,\n",
       "                       0.0704,  0.5760,  0.0448, -0.0093, -0.2898, -0.2884, -0.1911, -0.4178,\n",
       "                      -0.3498, -0.1361,  0.0738,  0.0428, -0.4590, -0.2872,  0.9454,  0.2477,\n",
       "                      -0.3595, -0.0502, -0.2472, -0.3966, -0.1140, -0.2729, -0.1293, -0.2641,\n",
       "                       0.2529,  0.0764, -0.2318, -0.1059,  0.0071, -0.2998,  0.2809,  0.1078,\n",
       "                       0.0868, -0.2328, -0.0627, -0.0959,  0.3230, -0.1835, -0.3357,  0.4996],\n",
       "                     device='mps:0')),\n",
       "             ('event_tower.6.weight',\n",
       "              tensor([0.6376, 1.2950, 0.9169, 1.0948, 0.5389, 0.6105, 0.7904, 1.0036, 0.5661,\n",
       "                      0.9455, 1.0407, 1.1670, 0.8655, 0.6963, 0.5375, 0.4240, 1.4198, 1.2107,\n",
       "                      1.2539, 1.0198, 1.2729, 0.5702, 1.0053, 1.0392, 1.2484, 0.9091, 1.0760,\n",
       "                      1.2375, 1.2525, 0.9371, 0.7418, 0.6375, 1.3694, 0.5713, 1.2670, 0.9305,\n",
       "                      1.1491, 0.9495, 0.7738, 1.2258, 0.9484, 1.0163, 1.0333, 0.8198, 0.8541,\n",
       "                      0.8939, 0.8991, 0.8154, 1.1018, 1.1229, 1.0845, 0.9231, 1.1391, 0.7143,\n",
       "                      1.3741, 1.1599, 1.0665, 0.8380, 1.0836, 0.8486, 1.3568, 1.7179, 0.9521,\n",
       "                      0.7765, 0.9822, 1.2605, 1.2368, 1.3492, 0.3734, 0.7063, 1.2044, 1.1804,\n",
       "                      0.9766, 0.6675, 0.8092, 0.6650, 0.9372, 0.9538, 1.1801, 0.9100, 1.1101,\n",
       "                      1.0213, 0.8008, 0.9108, 1.0491, 1.1130, 1.1345, 0.9876, 0.7753, 1.2164,\n",
       "                      0.4950, 0.9705, 1.0616, 1.1351, 1.2561, 1.0506, 2.2184, 0.6636, 0.9730,\n",
       "                      1.1522, 1.7019, 1.0724, 1.2216, 0.8866, 0.7482, 0.9441, 1.3126, 0.7800,\n",
       "                      0.6448, 1.0096, 0.8790, 0.9752, 1.3245, 1.1451, 0.9631, 1.4365, 0.7191,\n",
       "                      1.1533, 1.2093, 0.4828, 1.0359, 0.9802, 1.0628, 1.1575, 1.3047, 0.8091,\n",
       "                      1.1353, 1.1470], device='mps:0')),\n",
       "             ('event_tower.6.bias',\n",
       "              tensor([ 3.3247e-02, -1.1623e-01, -8.8364e-02,  1.9831e-02,  8.3549e-02,\n",
       "                       2.4001e-01,  7.2425e-02,  2.4295e-01,  7.6449e-03,  1.9991e-01,\n",
       "                      -1.6082e-02,  3.4773e-02, -1.8399e-02,  4.6159e-02, -1.3946e-01,\n",
       "                      -8.7758e-02,  1.6276e-01,  1.9861e-01,  2.8846e-01,  1.7680e-01,\n",
       "                       5.6958e-02,  1.8777e-01, -1.7986e-02,  1.3992e-01,  2.1640e-01,\n",
       "                      -8.3270e-02, -2.1833e-01,  2.9117e-01,  1.8622e-01,  2.9018e-01,\n",
       "                       2.3228e-01,  3.9914e-02,  1.5995e-01, -1.6048e-01,  1.5313e-01,\n",
       "                      -1.4270e-01, -1.6614e-01,  1.8233e-01, -2.0587e-02,  2.0503e-01,\n",
       "                       1.4214e-01,  5.8145e-02, -6.6241e-02, -1.9948e-02,  5.9873e-02,\n",
       "                      -8.0955e-02, -6.9831e-02, -1.4785e-01,  1.3834e-01,  1.1929e-01,\n",
       "                      -4.8725e-02, -5.1068e-02, -1.4332e-01,  6.6666e-02,  2.5395e-02,\n",
       "                       1.2455e-01, -1.7970e-01,  1.7992e-01,  1.0055e-01, -1.8646e-01,\n",
       "                       3.5523e-01,  2.0311e-01,  2.7456e-01, -3.0165e-02,  7.1456e-02,\n",
       "                      -5.1907e-02,  1.9070e-01,  1.1559e-01, -4.7292e-02,  2.3110e-01,\n",
       "                      -8.0239e-02,  1.2345e-04,  2.0216e-01,  1.0616e-01,  6.9628e-02,\n",
       "                      -6.7783e-03, -1.2447e-01, -5.3960e-03,  1.4197e-01, -1.1932e-01,\n",
       "                       1.7122e-01,  1.7777e-01,  3.2906e-02, -6.1018e-02,  9.9388e-02,\n",
       "                       1.9282e-01,  1.8829e-01,  2.0639e-01,  4.3936e-01,  5.4757e-02,\n",
       "                      -1.4521e-02, -5.8240e-02, -6.4303e-02, -2.0533e-02,  6.1068e-02,\n",
       "                      -8.7864e-02,  3.5663e-02,  1.3475e-01,  2.2595e-01,  2.9500e-01,\n",
       "                       3.1555e-01,  2.6847e-02, -3.9672e-02,  5.5851e-03,  1.9699e-01,\n",
       "                      -1.5612e-02, -5.3540e-02,  1.3126e-02,  2.8835e-01,  4.4157e-02,\n",
       "                       6.0051e-02,  1.9903e-02, -9.0316e-02,  1.1350e-01,  2.1626e-01,\n",
       "                       3.0783e-01, -3.4431e-02, -2.6718e-02,  1.8411e-01, -8.1235e-02,\n",
       "                       2.2539e-01,  1.1162e-01,  4.9701e-03,  1.0234e-01,  2.3145e-01,\n",
       "                       5.4168e-02,  1.8610e-02, -9.3179e-02], device='mps:0')),\n",
       "             ('event_tower.6.running_mean',\n",
       "              tensor([0.0000e+00, 0.0000e+00, 7.2057e+00, 1.1784e+00, 1.4705e+00, 3.8085e-01,\n",
       "                      8.9579e-01, 2.0527e+00, 4.1289e-01, 3.3865e-03, 7.8438e-01, 0.0000e+00,\n",
       "                      9.8882e+00, 0.0000e+00, 1.7177e+00, 9.5029e+00, 2.1071e+00, 2.4949e+00,\n",
       "                      2.9113e+00, 1.4535e+00, 6.8554e+00, 0.0000e+00, 5.4360e+00, 2.2391e-01,\n",
       "                      1.7114e+00, 4.7965e-01, 1.1205e+01, 2.2137e+00, 2.1496e+00, 3.4349e+00,\n",
       "                      2.2371e+00, 4.2044e+00, 1.0206e-24, 2.3586e+00, 2.0723e+00, 9.2532e+00,\n",
       "                      8.6565e+00, 9.6006e-01, 4.8327e+00, 2.0290e+00, 5.7416e+00, 4.2678e-11,\n",
       "                      7.9632e+00, 9.7372e+00, 1.1108e+00, 0.0000e+00, 0.0000e+00, 1.9721e+00,\n",
       "                      7.4517e-01, 3.6231e-14, 9.8825e+00, 2.6361e+00, 4.6252e-01, 2.8251e+00,\n",
       "                      0.0000e+00, 0.0000e+00, 5.6386e+00, 0.0000e+00, 8.9781e-01, 3.9069e-01,\n",
       "                      4.4323e-01, 1.5735e-03, 9.4201e+00, 1.7660e+00, 3.3183e+00, 6.7954e-02,\n",
       "                      1.9958e+00, 5.8053e-04, 7.7563e+00, 3.9896e+00, 6.3230e+00, 5.8995e+00,\n",
       "                      1.9551e+00, 2.8999e+00, 3.8293e+00, 2.8886e+00, 7.2649e+00, 1.1661e+00,\n",
       "                      9.6630e-02, 9.0918e-01, 5.8761e-23, 9.3365e-01, 1.2703e+00, 1.1085e+01,\n",
       "                      3.9766e+00, 1.0683e+00, 1.3444e+00, 4.6130e+00, 5.3748e+00, 5.9456e+00,\n",
       "                      3.1924e+00, 4.8742e+00, 0.0000e+00, 1.2444e-01, 1.8718e-01, 3.6081e-01,\n",
       "                      7.8970e-36, 2.4010e+00, 6.7792e-01, 4.5209e+00, 1.1709e-01, 0.0000e+00,\n",
       "                      8.3134e+00, 2.0642e+00, 6.8793e-01, 3.7745e+00, 1.4411e-17, 8.1283e-01,\n",
       "                      2.3949e+00, 4.9530e-01, 1.9317e+00, 0.0000e+00, 5.0685e+00, 8.4613e+00,\n",
       "                      2.2430e+00, 1.4940e-01, 2.6625e+00, 0.0000e+00, 1.8995e+00, 2.4596e+00,\n",
       "                      3.4438e+00, 0.0000e+00, 1.0336e+00, 5.7550e-01, 1.9265e+00, 0.0000e+00,\n",
       "                      0.0000e+00, 6.0561e+00], device='mps:0')),\n",
       "             ('event_tower.6.running_var',\n",
       "              tensor([0.0000e+00, 0.0000e+00, 3.1338e+01, 1.0087e+01, 7.8396e+00, 2.1612e+00,\n",
       "                      5.1647e+00, 1.0433e+01, 3.0182e+00, 2.2066e-03, 4.9061e+00, 0.0000e+00,\n",
       "                      4.5880e+01, 0.0000e+00, 6.2136e+00, 2.7205e+01, 9.6068e+00, 6.7432e+00,\n",
       "                      1.1867e+01, 6.3748e+00, 5.3616e+01, 0.0000e+00, 3.4371e+01, 4.7260e-01,\n",
       "                      6.2861e+00, 1.5805e+00, 3.8616e+01, 1.0500e+01, 7.1915e+00, 2.9061e+01,\n",
       "                      1.3986e+01, 3.8592e+01, 1.0525e-25, 1.3079e+01, 1.1313e+01, 3.0415e+01,\n",
       "                      3.3083e+01, 6.6497e+00, 2.9076e+01, 6.6964e+00, 6.0677e+01, 1.1909e-11,\n",
       "                      1.0533e+02, 4.1698e+01, 6.8741e+00, 0.0000e+00, 0.0000e+00, 1.7438e+01,\n",
       "                      1.6447e+00, 2.9491e-14, 1.0581e+02, 1.4286e+01, 7.2199e-01, 2.0687e+01,\n",
       "                      0.0000e+00, 0.0000e+00, 6.5716e+01, 0.0000e+00, 5.1805e+00, 1.2858e+00,\n",
       "                      1.6264e+00, 3.6539e-03, 6.0973e+01, 1.3317e+01, 2.6513e+01, 1.8967e-01,\n",
       "                      8.4378e+00, 3.7043e-04, 1.3267e+01, 2.4656e+01, 4.0574e+01, 3.5937e+01,\n",
       "                      9.5730e+00, 2.5161e+01, 2.5637e+01, 3.1957e+01, 2.5169e+01, 4.8005e+00,\n",
       "                      4.8774e-01, 6.5171e+00, 1.0742e-22, 7.2028e+00, 5.8855e+00, 4.2757e+01,\n",
       "                      2.7511e+01, 2.6875e+00, 7.9173e+00, 9.1785e+00, 3.9171e+01, 3.7159e+01,\n",
       "                      2.2644e+01, 4.8488e+01, 0.0000e+00, 3.7821e-01, 4.5983e-01, 1.2489e+00,\n",
       "                      5.1672e-37, 2.1045e+01, 2.8088e+00, 4.7005e+01, 3.2146e-01, 0.0000e+00,\n",
       "                      3.6582e+01, 7.8765e+00, 4.0944e+00, 3.8031e+01, 2.0697e-17, 5.1170e+00,\n",
       "                      1.6368e+01, 3.3808e+00, 1.4145e+01, 0.0000e+00, 1.0101e+01, 1.1656e+02,\n",
       "                      1.1550e+01, 4.1866e-01, 1.1240e+01, 0.0000e+00, 8.0247e+00, 1.6454e+01,\n",
       "                      3.2487e+01, 0.0000e+00, 2.9872e+00, 2.0726e+00, 8.2063e+00, 0.0000e+00,\n",
       "                      0.0000e+00, 3.9040e+01], device='mps:0')),\n",
       "             ('event_tower.6.num_batches_tracked',\n",
       "              tensor(45010, device='mps:0')),\n",
       "             ('event_tower.8.weight',\n",
       "              tensor([[-2.7155e-02,  1.3986e-01, -1.5357e-01,  ...,  5.4010e-02,\n",
       "                       -9.0148e-03, -1.7889e-01],\n",
       "                      [ 3.4255e-02,  6.6161e-02, -3.4137e-01,  ..., -1.0200e-01,\n",
       "                        2.5967e-02, -2.8454e-01],\n",
       "                      [ 1.2568e-01,  2.1411e-01, -3.0578e-01,  ...,  8.1058e-02,\n",
       "                       -4.2957e-02, -2.4235e-01],\n",
       "                      ...,\n",
       "                      [ 1.2340e-01,  2.2273e-01, -3.0040e-01,  ...,  1.0383e-02,\n",
       "                        1.3373e-01, -1.6496e-01],\n",
       "                      [-2.2958e-02, -1.3124e-01,  5.5991e-02,  ..., -2.2324e-02,\n",
       "                       -3.3628e-01,  2.4446e-01],\n",
       "                      [-2.3552e-02, -8.5104e-02,  1.5046e-01,  ..., -1.2922e-01,\n",
       "                        1.0703e-04,  2.2654e-01]], device='mps:0')),\n",
       "             ('event_tower.8.bias',\n",
       "              tensor([ 0.0737, -0.0444, -0.0672,  0.0369, -0.0547, -0.0806, -0.0783, -0.0437,\n",
       "                       0.0185, -0.0255, -0.0897, -0.0676, -0.0683,  0.0373,  0.0020, -0.0764,\n",
       "                       0.0454,  0.0743, -0.0542, -0.0637,  0.0446,  0.0795, -0.0275, -0.0085,\n",
       "                      -0.0751,  0.0196,  0.0208,  0.0088, -0.0584, -0.0061,  0.0603, -0.0695,\n",
       "                       0.0458, -0.0203, -0.0076,  0.1108, -0.0117, -0.0278,  0.0726, -0.0005,\n",
       "                       0.0783, -0.0293, -0.0351, -0.0706, -0.0748,  0.0774,  0.0754,  0.0434,\n",
       "                      -0.0270,  0.0274,  0.0443,  0.0371, -0.0465,  0.0589, -0.0931,  0.0488,\n",
       "                      -0.0707,  0.0598, -0.0726, -0.0111,  0.0389,  0.0218, -0.0412,  0.0754],\n",
       "                     device='mps:0')),\n",
       "             ('event_tower.9.weight',\n",
       "              tensor([0.3454, 0.5084, 0.4422, 0.3940, 0.5070, 0.4097, 0.3452, 0.4703, 0.4339,\n",
       "                      0.4115, 0.3790, 0.3678, 0.6991, 0.3635, 0.4534, 0.4541, 0.3915, 0.4584,\n",
       "                      0.4280, 0.4514, 0.4599, 0.4429, 0.4041, 0.4775, 0.3084, 0.7541, 0.4349,\n",
       "                      0.6203, 0.7181, 0.5523, 0.6329, 0.5552, 0.3864, 0.5260, 0.5255, 0.4998,\n",
       "                      0.4451, 0.6561, 0.3566, 0.4617, 0.6362, 0.5142, 0.4972, 0.3842, 0.3220,\n",
       "                      0.4644, 0.4148, 0.4990, 0.4047, 0.4010, 0.4351, 0.4458, 0.4390, 0.4944,\n",
       "                      0.6213, 0.4765, 0.5681, 0.4103, 0.5153, 0.5875, 0.5805, 0.4435, 0.4881,\n",
       "                      0.4608], device='mps:0')),\n",
       "             ('event_tower.9.bias',\n",
       "              tensor([ 0.2820, -0.0820, -0.0428,  0.1398, -0.0247, -0.1605, -0.2350, -0.2747,\n",
       "                      -0.2243, -0.0166, -0.1182,  0.1652, -0.0524, -0.4256,  0.2361,  0.1466,\n",
       "                      -0.1910,  0.3701,  0.1920,  0.0463, -0.2892,  0.3203, -0.3027,  0.0684,\n",
       "                       0.6811, -0.3223, -0.4462,  0.2038,  0.0245,  0.0855,  0.2962,  0.1255,\n",
       "                      -0.2157,  0.0398,  0.1937, -0.2289,  0.1221, -0.2305, -0.3807, -0.3862,\n",
       "                       0.0689, -0.4150, -0.0429, -0.2477, -0.4610,  0.1567, -0.4244,  0.0615,\n",
       "                       0.1235,  0.2684, -0.0133, -0.0106,  0.1449, -0.0568,  0.4804, -0.4518,\n",
       "                       0.0872, -0.2317, -0.1356, -0.0716, -0.1548,  0.4494, -0.2484,  0.0245],\n",
       "                     device='mps:0')),\n",
       "             ('event_tower.9.running_mean',\n",
       "              tensor([ 1.1727, -0.3292,  0.2747, -0.8724, -0.6981,  0.8485, -1.0254, -0.9724,\n",
       "                       0.3235, -0.1238, -0.5494, -0.3168, -1.1986, -0.2481, -1.2986,  0.2068,\n",
       "                      -0.9338, -0.0454, -0.5895, -0.0343, -0.1055,  1.2753, -0.7142,  0.5249,\n",
       "                       0.2292, -0.8556,  0.8374,  0.6000, -0.7634,  0.3373,  0.7801,  0.5327,\n",
       "                      -1.3698,  0.6067, -0.7604, -0.0120, -0.2001,  0.7692, -0.0802,  0.8294,\n",
       "                       0.7904,  1.0738, -0.3029, -1.3966,  0.0370, -1.5167,  0.6047, -0.5601,\n",
       "                      -0.5183, -0.5897,  0.2901,  0.7952, -1.5094, -0.2198, -0.8324, -1.3421,\n",
       "                       0.6844,  0.4857, -0.7230,  1.0699,  0.9518,  0.4917,  0.8473, -0.3744],\n",
       "                     device='mps:0')),\n",
       "             ('event_tower.9.running_var',\n",
       "              tensor([154.1405, 123.2577, 163.4686, 153.7941,  76.9901, 158.0845, 157.8353,\n",
       "                       22.3827, 152.1235, 116.3746, 135.5476, 147.5721,  19.4598, 114.2227,\n",
       "                      119.4446, 149.8170, 156.0199, 122.7893, 152.2830, 127.0094,  68.1212,\n",
       "                      152.8315,  26.5243,  68.6133, 108.8078,  23.9799,  45.6746,  47.8912,\n",
       "                        9.5956, 120.8453,  58.0480, 106.9805,  69.9390, 102.6974,  38.9609,\n",
       "                      116.0400, 145.4660,  30.1144, 114.7772,  65.3851,  90.7229,  47.2024,\n",
       "                       53.9107, 105.7549,  95.0638, 112.1359, 134.5412,  69.8200, 133.9891,\n",
       "                      142.0577, 108.7718, 164.4776, 106.6103, 142.6678,  44.4712, 134.7399,\n",
       "                       65.4235, 119.9421, 109.6643,  18.4259,  55.6617, 153.0795,  54.4762,\n",
       "                      155.7675], device='mps:0')),\n",
       "             ('event_tower.9.num_batches_tracked',\n",
       "              tensor(45010, device='mps:0'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_REGISTRY = pathlib.Path().cwd().parent / 'model_registry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to: /Users/sudhamshuaddanki/smaddanki/Assessments/Whizdomai/model_registry/two_tower_10_001_80_250130.pth\n"
     ]
    }
   ],
   "source": [
    "model_save_path = MODEL_REGISTRY / 'two_tower_10_001_80_250130.pth'\n",
    "\n",
    "# Save the model state_dict()\n",
    "print(f\"[INFO] Saving model to: {model_save_path}\")\n",
    "torch.save(obj=model,\n",
    "            f=model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
